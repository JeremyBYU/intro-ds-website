[
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Intro to Data Science",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project Description (Core Capstone)",
    "section": "",
    "text": "Topic ideas due Wed, Feb 22\nProposal due Wed, Mar 22\nDraft report due Wed, Apr 12\nPeer review due Wed, Apr 19\nFinal report due Friday, Apr 28\nFinal Presentation due Final Exam Day"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project Description (Core Capstone)",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression or classification analysis.\nThe goal of the final project is for you to use data science methods to analyze data of your choosing. The data should broadly connect to topics you studied in the Core Curriculum (first-year seminar, foundations for the future and understanding the world domains, and the themed explorations). The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class and apply them to a data set to analyze it in a meaningful way.\nThis project will be your Core Capstone work. A Core Capstone Work is an assignment (or set of assignments) in students’ major capstone/seminar course where students integrate their Core Curriculum coursework with their major course work. Students will use their collected Signature Assignments (one assignment from each Core course, collected in Brightspace ePortfolios) to help in this work. This Core Capstone work will have six (6) deliverables that fulfill the learning outcomes of the Core Capstone."
  },
  {
    "objectID": "project-description.html#deliverables",
    "href": "project-description.html#deliverables",
    "title": "Project Description (Core Capstone)",
    "section": "Deliverables",
    "text": "Deliverables\nThe six deliverables for the final project are\n\nTopic Ideas - Identify 2-3 data sets that connect with the topics you covered in the Core Curriculum. Write a brief report of the data (Core Capstone Work LO1 and L02).\nProposal - Begin your analysis of your chosen dataset and its connection with two (2) of your signature assignments (Core Capstone Work LO1 and L02)\nDraft Report - First draft of your final report (Core Capstone Work LO1 and LO2)\nPeer Review - Formal peer review on another students project. This will provide important feedback to others and provide you an opportunity to serve and aid others (Core Capstone Work LO3).\nFinal Report - A written, reproducible report detailing your analysis (Core Capstone Work LO1). Include an ending discussion of how your coursework has helped you to be a leader in service to others (Core Capstone Work LO3)\nFinal Presentation - A brief 7-10 minutes presentation that summarizes your work (Core Capstone Work LO1).\n\nAll analyses must be done in Jupyter Notebooks stored in a shared Google Drive Folder. All components of the project must be reproducible (written in Google Collab notebook), except the presentation. The template for all deliverables can be found in here. You should copy each template component into your shared google drive folder and complete the assignment."
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project Description (Core Capstone)",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you’re interested in potentially using for the final project that connect with the topics you covered in the Core Curriculum. If you’re unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. Example project ideas and datasets can be found in the Example Project Ideas section. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by me.\nThe data sets should meet the following criteria:\n\nAt least 100 observations\nAt least 7 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable\n\nThe response variable can be quantitative or categorical.\nThis is the most important part of the dataset! Please identify this variable (column) and be clear that it is your response variable in your topic idea report!\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\n\nPlease ask me if you’re unsure whether your data set meets the criteria.\nPlease write a report in the file topic-ideas.ipynb which is in you shared Google Drive folder. Include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nDescribe the observations and the general characteristics being measured in the data.\nDescribe how the data set connect to your Core Studies.\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data. Remember the main focus of this class is to make a predictive model. You shoud frame the question as, “Can one reliabily predict X from Y”. Where X is some column in your dataset and Y are 6 or more different columns in your dataset.\n\n\n\nGlimpse of data\n\nUse the info function to provide an overview of each data set\n\nPrint your Jupyter notebook as PDF and submit to Brightspace\n\n\nSave Dataset\nPlease save each dataset in the data folder in your Google Drive Folder."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project Description (Core Capstone)",
    "section": "Project proposal",
    "text": "Project proposal\nPlease write a report in the file project-proposal.ipynb which is in you shared Google Drive folder.\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating\nthe motivation for your research question (citing any relevant literature)\nbriefyly describe its connection to Core classes\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nModel selection (linear regresssion, logistic regression, k-nearest neighbors, support vector machine, etc.)\n\n\n\nSection 4 - Connect to Core Capstone Work\nDescribe how this dataset and analysis will connect with at least two (2) your signature assignments from the Core (Core Capstone Work LO2)\n\nDescribe each signature assignment\nDescribe how the dataset and analysis builds upon or connects with your prior work\n\nExample: You took Philosphy 106 (ethics) and you discussed the relationship between employers and employees. You submitted a signature assignment of a paper on unions (pro or against, it doesn’t matter). A possible dataset you could choose is the Right to Work Dataset and do an analysis on the relationship between state laws and their effect on union participation.\n\n\nSection 5 - Data dictionary (aka code book)\nIn this section, you will create a markdown table that describes each varible in the dataset. Put your da in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPrint your Jupyter notebook as a PDF and submit to Brightspace.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project Description (Core Capstone)",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.ipynb file in your shared Google Drive folder. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Include this papers connection to at least two core classes. Describe the data and definitions of key variables. It should also include some exploratory data analysis (EDA). All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults and Discussion\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics. If you are doing a classificaiton problem please include a confusion matrix.\nThis section also includes initial interpretations and conclusions drawn from the model.\nSubmission\nPrint your Jupyter notebook as a PDF and submit to Brightspace."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project Description (Core Capstone)",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others’ work is a crucial part of the scientific process. Each invidual/team will be assigned two other teams’s projects to review. Each team should have finished their draft report by the due date. A class period in the following week will be dedicated to the peer review, and all reviews will be due by the end of that class session.\nThe peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\nI will assign which two teams your team will reivew shortely before the peer reivew process begins\n\nProcess and questions\nWrite your reviews inside your shared Google Drive folder called peer-review. Inside will be two Google documents for you to fill out for each team you review. Please ensure each review has the following:\n-   Names of team members that participated in this review: \\[FULL NAMES OF TEAM MEMBERS DOING THE REVIEW\\]\n\n-   Describe the goal of the project.\n\n-   Describe the data used or collected, if any.\n    If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\n\n-   Describe the approaches, tools, and methods that will be used.\n\n-   Is there anything that is unclear from the proposal?\n\n-   Provide constructive feedback on how the team might be able to improve their project.\n    Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\n\n-   What aspect of this project are you most interested in and would like to see highlighted in the presentation.\n\n-   Provide constructive feedback on any issues with file and/or code organization.\n\n-   (Optional) Any further comments or feedback?\nSubmission\nPrint your Google Docs as a PDF and submit to Brightspace. You should have two uploads for each team you review."
  },
  {
    "objectID": "project-description.html#final-report",
    "href": "project-description.html#final-report",
    "title": "Project Description (Core Capstone)",
    "section": "Final report",
    "text": "Final report\nYour written report must be completed in the written-report.ipynb file and must be reproducible. All team members should contribute to the report\nYou will submit the PDF of your final report on Brightspace.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Include this papers connection to at least two core classes. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients or behavrior are used to support the key findings and conclusions. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed including the use of RMSE or confusion matrices.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Please also inlcude an ending discussion of how your coursework has helped (or prepared) you to be a leader in service to others\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\nSubmission\nExport your Jupyter notebook as a PDF and submit to Brightspace."
  },
  {
    "objectID": "project-description.html#presentation-slides",
    "href": "project-description.html#presentation-slides",
    "title": "Project Description (Core Capstone)",
    "section": "Presentation + slides",
    "text": "Presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYour slides should be Google Slides and be created in your shared Google Drive folder presentation-slides\nThe slide deck should have no more than 8 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 8 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Highlights from EDA\nSlide 5: Final model\nSlide 6: Final model\nSlide 7: Interesting findings from the model\nSlide 8: Conclusions + future work\n\nSubmission\nExport your slides as a PDF and submit to brightsapce"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project Description (Core Capstone)",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the shared Google Drive should be neatly organized.\nHere is an example of how it should be organized:\n\n\n\nExample Google Drive Format\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the Google Drive folder."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project Description (Core Capstone)",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n15 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n45 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-description.html#example-project-ideas",
    "href": "project-description.html#example-project-ideas",
    "title": "Project Description (Core Capstone)",
    "section": "Example Project Ideas",
    "text": "Example Project Ideas\n\nYou took Philosphy 106 (ethics) and you discussed the relationship between employers and employees. You submitted a signature assignment of a paper on unions (pro or against, it doesn’t matter). A possible dataset you could choose is the Right to Work Dataset and do an analysis on the relationship between state laws and their effect on union participation.\nYou took a BIO 101 class and discussed the biologcal mechanisms of diabetes. A possible dataset you could choose is the Diabetes Dataset and create a model that predict diabetes based on diagnostic measurements.\nYou took ARTS 104 (Creativity: Methods and Practices). A possible dataset you could choose is the Best Artworks of All Time and do a clustering analysis to see if there exists any patterns about great artists in our times (country, age, sex, etc.).\nYou took SOCIO 101. A possible dataset you could choose is the Student Performance Dataset that looks at student achievement in secondary education. You could create a regression model that predicts performance based upon a variety of factors."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "You took Philosphy 106 (ethics) and you discussed the relationship between employers and employees. You submitted a signature assignment of a paper on unions (pro or against, it doesn’t matter). A possible dataset you could choose is the Right to Work Dataset and do an analysis on the relationship between state laws and their effect on union participation.\nYou took a BIO 101 class and discussed the biologcal mechanisms of diabetes. A possible dataset you could choose is the Diabetes Dataset and create a model that predict diabetes based on diagnostic measurements.\nYou took ARTS 104 (Creativity: Methods and Practices). A possible dataset you could choose is the Best Artworks of All Time and do a clustering analysis to see if there exists any patterns about great artists in our times (country, age, sex, etc.).\nYou took SOCIO 101. A possible dataset you could choose is the Student Performance Dataset that looks at student achievement in secondary education. You could create a regression model that predicts performance based upon a variety of factors.\n\n\n\n\n\nKaggle Datasets\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\nTODO example plot\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "Week\nSlides\nClass Activity\nHW\n\n\n\n\nWeek 1\n🖥️ 🖥️\n📋\n⌨️\n\n\nWeek 2\n🖥️ 🖥️\n📋\n⌨️\n\n\nWeek 3\n🖥️ 🖥️\n📋\n⌨️\n\n\nWeek 4\n🖥️ 🖥️\n📋\n⌨️\n\n\nWeek 5\n🖥️\nNone\nNone\n\n\nWeek 6\n🖥️ 🖥️\n📋\n⌨️\n\n\nWeek 7\n🖥️ 🖥️\n📋\n⌨️ ⌨️\n\n\nWeek 8\n🖥️ 🖥️\n📋\n⌨️\n\n\nWeek 9\n\n\n\n\n\nWeek 10\n\n\n\n\n\nWeek 11\n\n\n\n\n\nWeek 12\n\n\n\n\n\nWeek 13\n\n\n\n\n\nWeek 14\n\n\n\n\n\nWeek 15\n\n\n\n\n\nWeek 16"
  },
  {
    "objectID": "slides/lec-11.html#schedule",
    "href": "slides/lec-11.html#schedule",
    "title": "CISC482 - Lecture11",
    "section": "Schedule",
    "text": "Schedule\n\nTopic Ideas - Should be turned in! Will grade soon!\nReading 5-3: Mar 01 @ 12PM, Wednesday\nHW4 - Mar 08 @ Midnight\nProposal: Mar 22, Wednesday"
  },
  {
    "objectID": "slides/lec-11.html#today",
    "href": "slides/lec-11.html#today",
    "title": "CISC482 - Lecture11",
    "section": "Today",
    "text": "Today\n\nAssumptions of Linear Regression\nMultiple Linear Regression"
  },
  {
    "objectID": "slides/lec-11.html#review-simple-linear-regression",
    "href": "slides/lec-11.html#review-simple-linear-regression",
    "title": "CISC482 - Lecture11",
    "section": "Review Simple Linear Regression",
    "text": "Review Simple Linear Regression\n\n\nWhat is the model for linear regresion: \\(\\hat{y} = ?\\)\nWhat is residual?\nWhat is the loss function to solve for the parameters\n\n\\(L(\\beta_0, \\beta_1) = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2\\)\n\\(L(\\beta_0, \\beta_1) = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2\\)"
  },
  {
    "objectID": "slides/lec-11.html#formulas",
    "href": "slides/lec-11.html#formulas",
    "title": "CISC482 - Lecture11",
    "section": "Formulas?",
    "text": "Formulas?\n\\(\\beta_1 (slope) = \\frac{\\sum\\limits_{i=1}^{n}[(x_i-\\bar{x})(y_i- \\bar{y})]}{\\sum\\limits_{i=1}^{n} (x_i - \\bar{x})^2}\\)\n\\(\\beta_0\\) (intercept) = \\(\\bar{y} - \\beta_1 \\bar{x}\\) \n\n\n\\(\\hat{\\beta}_1 (slope) = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_y}{s_x}\\)\n\\(\\beta_0\\) (intercept) = \\(\\bar{y} - \\beta_1 \\bar{x}\\)"
  },
  {
    "objectID": "slides/lec-11.html#assumptions-of-linear-regression",
    "href": "slides/lec-11.html#assumptions-of-linear-regression",
    "title": "CISC482 - Lecture11",
    "section": "Assumptions of Linear Regression",
    "text": "Assumptions of Linear Regression\n\n\\(x\\) and \\(y\\) have a linear relationship.\nThe residuals of the observations are independent.\nThe mean of the residuals is 0 and the variance of the residuals is constant.\nThe residuals are approximately normally distributed."
  },
  {
    "objectID": "slides/lec-11.html#linear-relationship",
    "href": "slides/lec-11.html#linear-relationship",
    "title": "CISC482 - Lecture11",
    "section": "Linear Relationship?",
    "text": "Linear Relationship?"
  },
  {
    "objectID": "slides/lec-11.html#residual-plot",
    "href": "slides/lec-11.html#residual-plot",
    "title": "CISC482 - Lecture11",
    "section": "Residual Plot",
    "text": "Residual Plot\n\n\nCode\nax = sns.residplot(x=x,y=y)\nax.set_xlabel(\"X\")\nax.set_ylabel(\"Residuals\");"
  },
  {
    "objectID": "slides/lec-11.html#independence-of-error",
    "href": "slides/lec-11.html#independence-of-error",
    "title": "CISC482 - Lecture11",
    "section": "Independence of Error",
    "text": "Independence of Error\n\nThe distances from the regression line to the points (residuals) should generally be random.\nYou do not want to see patterns\nWas the previous plot of residual showing patterns, or was it more or less random?"
  },
  {
    "objectID": "slides/lec-11.html#residual-are-independent",
    "href": "slides/lec-11.html#residual-are-independent",
    "title": "CISC482 - Lecture11",
    "section": "Residual are independent?",
    "text": "Residual are independent?"
  },
  {
    "objectID": "slides/lec-11.html#examples-of-dependence",
    "href": "slides/lec-11.html#examples-of-dependence",
    "title": "CISC482 - Lecture11",
    "section": "Examples of Dependence",
    "text": "Examples of Dependence\n\nTime dependence can often be assessed by analyzing the scatter plot of residuals over time.\nSpatial dependence can often be assessed by analyzing a map of where the data was collected along with further inspection of the residuals for spatial patterns.\nDependencies between observational units must be assessed in context of the study."
  },
  {
    "objectID": "slides/lec-11.html#example---time",
    "href": "slides/lec-11.html#example---time",
    "title": "CISC482 - Lecture11",
    "section": "Example - Time",
    "text": "Example - Time"
  },
  {
    "objectID": "slides/lec-11.html#example---space",
    "href": "slides/lec-11.html#example---space",
    "title": "CISC482 - Lecture11",
    "section": "Example - Space",
    "text": "Example - Space"
  },
  {
    "objectID": "slides/lec-11.html#discussion",
    "href": "slides/lec-11.html#discussion",
    "title": "CISC482 - Lecture11",
    "section": "Discussion",
    "text": "Discussion\n\nIn these graphs we saw time and spatial dependencies in our data set.\nWe saw this by plotting residual plots and looking for any patterns.\nRecall the model was: \\(MPG = m \\cdot Weight + b\\)\nDoes the independence of error assumption hold in this model?\nDoes that mean we should never use this model?"
  },
  {
    "objectID": "slides/lec-11.html#keeping-error-low-and-consistent",
    "href": "slides/lec-11.html#keeping-error-low-and-consistent",
    "title": "CISC482 - Lecture11",
    "section": "Keeping error low and consistent",
    "text": "Keeping error low and consistent\n\nThe residuals of a fitted linear model has a mean of 0. Always.\nA mean of 0 means that on average the predicted value is equal to to the observed value."
  },
  {
    "objectID": "slides/lec-11.html#example-residual-0",
    "href": "slides/lec-11.html#example-residual-0",
    "title": "CISC482 - Lecture11",
    "section": "Example, Residual 0",
    "text": "Example, Residual 0"
  },
  {
    "objectID": "slides/lec-11.html#example-residual-1",
    "href": "slides/lec-11.html#example-residual-1",
    "title": "CISC482 - Lecture11",
    "section": "Example, Residual 1",
    "text": "Example, Residual 1\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nLook at the y-axis scale!"
  },
  {
    "objectID": "slides/lec-11.html#consistent-variance",
    "href": "slides/lec-11.html#consistent-variance",
    "title": "CISC482 - Lecture11",
    "section": "Consistent Variance",
    "text": "Consistent Variance\n\nA linear regression should have a constant variance for all levels of the input.\nThat means the spread of the error should be the same at all levels of input\nLevel of input = x axis changing"
  },
  {
    "objectID": "slides/lec-11.html#example-residual-3",
    "href": "slides/lec-11.html#example-residual-3",
    "title": "CISC482 - Lecture11",
    "section": "Example, Residual 3",
    "text": "Example, Residual 3"
  },
  {
    "objectID": "slides/lec-11.html#example-residual-4",
    "href": "slides/lec-11.html#example-residual-4",
    "title": "CISC482 - Lecture11",
    "section": "Example, Residual 4",
    "text": "Example, Residual 4\n\n\n\n\n\n\n\n\n\n\n\nDanger\n\n\nClearly see a huge jump in variance around 15"
  },
  {
    "objectID": "slides/lec-11.html#example-mpg-prediction",
    "href": "slides/lec-11.html#example-mpg-prediction",
    "title": "CISC482 - Lecture11",
    "section": "Example, MPG Prediction",
    "text": "Example, MPG Prediction"
  },
  {
    "objectID": "slides/lec-11.html#normality-of-errors",
    "href": "slides/lec-11.html#normality-of-errors",
    "title": "CISC482 - Lecture11",
    "section": "Normality of Errors",
    "text": "Normality of Errors\n\n\nAs long as the previous assumptions hold you are going to get a good simple linear regression model\n\n\\(x\\) and \\(y\\) have a linear relationship\nErrors are independent (no spatial, time dependence, or other feature dependence)\nResidual mean of 0, variance constant\n\nHowever, if the errors are also normally distributed, more awesomeness can be done: Interval Estimates"
  },
  {
    "objectID": "slides/lec-11.html#interval-estimates",
    "href": "slides/lec-11.html#interval-estimates",
    "title": "CISC482 - Lecture11",
    "section": "Interval Estimates",
    "text": "Interval Estimates"
  },
  {
    "objectID": "slides/lec-11.html#full-example",
    "href": "slides/lec-11.html#full-example",
    "title": "CISC482 - Lecture11",
    "section": "Full Example",
    "text": "Full Example\n\nUse library numpy and scikit-learn to fit our models\nscikit-learn is library made for machine learning. Its awesome!"
  },
  {
    "objectID": "slides/lec-11.html#creating-data",
    "href": "slides/lec-11.html#creating-data",
    "title": "CISC482 - Lecture11",
    "section": "Creating data",
    "text": "Creating data\n\nn = 250\nx = np.arange(n)\nnoise = np.random.normal(loc=0, scale=5, size=n)\ny = (1.5 * x + 4) + noise\nax = sns.scatterplot(x=x,y=y);\nax.set_xlabel(\"X\")\nax.set_ylabel(\"Y\");"
  },
  {
    "objectID": "slides/lec-11.html#creating-data-output",
    "href": "slides/lec-11.html#creating-data-output",
    "title": "CISC482 - Lecture11",
    "section": "Creating data",
    "text": "Creating data"
  },
  {
    "objectID": "slides/lec-11.html#fitting-the-data",
    "href": "slides/lec-11.html#fitting-the-data",
    "title": "CISC482 - Lecture11",
    "section": "Fitting the data",
    "text": "Fitting the data\n\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\n\nX = x[:, np.newaxis] # n X 1 matrix\nreg = model.fit(X, y) # X needs to be a matrix\n\nslope, intercept  = reg.coef_[0], reg.intercept_\nprint(f\"Slope: {slope:.1f}; \\nIntercept: {intercept:.1f}\")\n\nax = sns.scatterplot(x=x, y=y)\nax.axline((0, intercept), slope=slope, color='r', label='Regressed Line');\nax.set_xlabel(\"X\")\nax.set_ylabel(\"Y\");"
  },
  {
    "objectID": "slides/lec-11.html#fitting-the-data-output",
    "href": "slides/lec-11.html#fitting-the-data-output",
    "title": "CISC482 - Lecture11",
    "section": "Fitting the data",
    "text": "Fitting the data\n\nSlope: 1.5; \nIntercept: 3.9"
  },
  {
    "objectID": "slides/lec-11.html#residual-plot-1",
    "href": "slides/lec-11.html#residual-plot-1",
    "title": "CISC482 - Lecture11",
    "section": "Residual Plot",
    "text": "Residual Plot\n\nfrom yellowbrick.regressor import ResidualsPlot\nmodel = LinearRegression()\nvisualizer = ResidualsPlot(model)\n\nvisualizer.fit(X, y) \nvisualizer.show();"
  },
  {
    "objectID": "slides/lec-11.html#residual-plot-1-output",
    "href": "slides/lec-11.html#residual-plot-1-output",
    "title": "CISC482 - Lecture11",
    "section": "Residual Plot",
    "text": "Residual Plot"
  },
  {
    "objectID": "slides/lec-11.html#definition",
    "href": "slides/lec-11.html#definition",
    "title": "CISC482 - Lecture11",
    "section": "Definition",
    "text": "Definition\n\nDataset has multiple input features\nIncorporate more than one input feature into a single regression equation -> multiple linear regression\n\\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + ... \\beta_k x_k\\)\n\\(x_1, ..., x_k\\) = input features\n\\(\\hat{y}\\) = predicted feature\n\\(\\beta_0\\) = y-intercept. \\(\\beta_1, ..., \\beta_k\\) = slopes"
  },
  {
    "objectID": "slides/lec-11.html#example",
    "href": "slides/lec-11.html#example",
    "title": "CISC482 - Lecture11",
    "section": "Example",
    "text": "Example\n\npp = sns.pairplot(data=df,\n                  height=7,\n                  y_vars=['body_mass_g'],\n                  x_vars=['bill_length_mm', 'flipper_length_mm'])"
  },
  {
    "objectID": "slides/lec-11.html#example-output",
    "href": "slides/lec-11.html#example-output",
    "title": "CISC482 - Lecture11",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/lec-11.html#d-plot",
    "href": "slides/lec-11.html#d-plot",
    "title": "CISC482 - Lecture11",
    "section": "3D plot",
    "text": "3D plot\n\nX = df[['bill_length_mm', 'flipper_length_mm']].values\ny = df['body_mass_g'].values\ndef plot_plane(x_coef, y_coef, intercept, ax):\n  x = np.linspace(X[:, 0].min(), X[:, 0].max(),  n)\n  y = np.linspace(X[:, 1].min(), X[:, 1].max(), n)\n  x, y = np.meshgrid(x, y)\n  eq = x_coef * x + y_coef * y + intercept\n  surface = ax.plot_surface(x, y, eq, color='red', alpha=0.5)\n\nfig = plt.figure(figsize = (10, 7))\nax = plt.axes(projection =\"3d\")\nax.scatter(X[:, 0], X[:, 1], y, label='penguins')\nax.set_xlabel(\"Bill Length\")\nax.set_ylabel(\"Flipper Length\")\nax.set_zlabel(\"Body Mass\")\nax.legend();"
  },
  {
    "objectID": "slides/lec-11.html#d-plot-output",
    "href": "slides/lec-11.html#d-plot-output",
    "title": "CISC482 - Lecture11",
    "section": "3D plot",
    "text": "3D plot"
  },
  {
    "objectID": "slides/lec-11.html#performing-regression",
    "href": "slides/lec-11.html#performing-regression",
    "title": "CISC482 - Lecture11",
    "section": "Performing Regression",
    "text": "Performing Regression\n\nmodel = LinearRegression()\nreg = model.fit(X, y) # X needs to be a matrix\n\nslope_bill, slope_flipper, intercept  = reg.coef_[0], reg.coef_[1], reg.intercept_\nprint(f\"Bill Slope: {slope:.1f}; Flipper Slope: {slope_flipper:.1f}; \\nIntercept: {intercept:.1f}\");\n\nBill Slope: 1.5; Flipper Slope: 48.9; \nIntercept: -5836.3"
  },
  {
    "objectID": "slides/lec-11.html#visualize-plane",
    "href": "slides/lec-11.html#visualize-plane",
    "title": "CISC482 - Lecture11",
    "section": "Visualize Plane",
    "text": "Visualize Plane\n\nfig = plt.figure(figsize = (10, 7))\nax = plt.axes(projection =\"3d\")\nax.scatter(X[:, 0], X[:, 1], y, label='penguins')\nax.set_xlabel(\"Bill Length\")\nax.set_ylabel(\"Flipper Length\")\nax.set_zlabel(\"Body Mass\")\nplot_plane(slope_bill, slope_flipper, intercept, ax=ax)\nax.legend();"
  },
  {
    "objectID": "slides/lec-11.html#visualize-plane-output",
    "href": "slides/lec-11.html#visualize-plane-output",
    "title": "CISC482 - Lecture11",
    "section": "Visualize Plane",
    "text": "Visualize Plane"
  },
  {
    "objectID": "slides/lec-11.html#simple-polynomial-regression",
    "href": "slides/lec-11.html#simple-polynomial-regression",
    "title": "CISC482 - Lecture11",
    "section": "Simple Polynomial Regression",
    "text": "Simple Polynomial Regression\n\nSpecial case of multiple linear regression\nInclude powers of a single features as inputs in the regression equation\nSimple polynomial linear regression\n\\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2 .. \\beta_k x^k\\)\nQuadratic: \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\)"
  },
  {
    "objectID": "slides/lec-11.html#example-quadratic",
    "href": "slides/lec-11.html#example-quadratic",
    "title": "CISC482 - Lecture11",
    "section": "Example Quadratic",
    "text": "Example Quadratic\n\n\nCode\nn = 30\nx = np.arange(n)\nnoise = np.random.normal(loc=0, scale=5, size=n)\ny = (0.1 * x**2  + 0.3 * x + 4) + noise\nsns.scatterplot(x=x,y=y);"
  },
  {
    "objectID": "slides/lec-11.html#fitting-a-quadratic-numpy",
    "href": "slides/lec-11.html#fitting-a-quadratic-numpy",
    "title": "CISC482 - Lecture11",
    "section": "Fitting a Quadratic (numpy)",
    "text": "Fitting a Quadratic (numpy)\n\ncoeffs = np.polyfit(x, y, deg=2)\nprint(coeffs); # beta_2, beta_1, beta_0\n\n[0.1 0.3 3.0]"
  },
  {
    "objectID": "slides/lec-11.html#plotting-your-regressed-polynomial-function",
    "href": "slides/lec-11.html#plotting-your-regressed-polynomial-function",
    "title": "CISC482 - Lecture11",
    "section": "Plotting your regressed polynomial function",
    "text": "Plotting your regressed polynomial function\n\n\nCode\nregressed_fn = np.poly1d(coeffs)\ny_hat = regressed_fn(x)\nax = sns.scatterplot(x=x,y=y)\nax.plot(x, y_hat, color='red', linestyle='--');"
  },
  {
    "objectID": "slides/lec-11.html#fitting-a-quadratic-scikit-learn",
    "href": "slides/lec-11.html#fitting-a-quadratic-scikit-learn",
    "title": "CISC482 - Lecture11",
    "section": "Fitting a Quadratic (SciKit Learn)",
    "text": "Fitting a Quadratic (SciKit Learn)\n\nScikit-learn can also fit polynomials\nYou must first create the additional columns manually\nIn other words create a second column that is the first column squared!\nHelpful class called PolynomialFeatures"
  },
  {
    "objectID": "slides/lec-11.html#fitting-a-quadratic-scikit-learn-1",
    "href": "slides/lec-11.html#fitting-a-quadratic-scikit-learn-1",
    "title": "CISC482 - Lecture11",
    "section": "Fitting a Quadratic (SciKit Learn)",
    "text": "Fitting a Quadratic (SciKit Learn)\n\nfrom sklearn.preprocessing import PolynomialFeatures\npf = PolynomialFeatures(degree=2,include_bias=False)\nX = x[:, np.newaxis] # n X 1 matrix\nx_features = pf.fit_transform(X)\nprint(\"Transformed Features:\\n\", x_features[:5, :])\nmodel = LinearRegression()\nreg = model.fit(x_features, y) # X needs to be a matrix\nprint(\"Coefficients\")\nprint(reg.coef_, reg.intercept_); # beta_2, beta_1, beta_0\n\nTransformed Features:\n [[0.0 0.0]\n [1.0 1.0]\n [2.0 4.0]\n [3.0 9.0]\n [4.0 16.0]]\nCoefficients\n[0.3 0.1] 2.965347007117529"
  },
  {
    "objectID": "slides/lec-11.html#plotting-your-regressed-polynomial-function-1",
    "href": "slides/lec-11.html#plotting-your-regressed-polynomial-function-1",
    "title": "CISC482 - Lecture11",
    "section": "Plotting your regressed polynomial function",
    "text": "Plotting your regressed polynomial function\n\n\nCode\nregressed_fn = np.poly1d(coeffs)\ny_hat = reg.predict(x_features)\nax = sns.scatterplot(x=x,y=y)\nax.plot(x, y_hat, color='red', linestyle='--');"
  },
  {
    "objectID": "slides/lec-11.html#class-activity-1",
    "href": "slides/lec-11.html#class-activity-1",
    "title": "CISC482 - Lecture11",
    "section": "Class Activity",
    "text": "Class Activity\nPractice Multiple Linear Regression\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-07.html#schedule",
    "href": "slides/lec-07.html#schedule",
    "title": "CISC482 - Lecture07",
    "section": "Schedule",
    "text": "Schedule\n\nReading 3-2: Feb 8 @ 12PM, Wednesday\nReading 4-1: Feb 10 @ 12PM, Friday\nReading 4-2: Feb 15 @ 12PM, Wednesday\nHW3: Feb 15 @ Midnight, Wednesday"
  },
  {
    "objectID": "slides/lec-07.html#cs-faculty-candidate",
    "href": "slides/lec-07.html#cs-faculty-candidate",
    "title": "CISC482 - Lecture07",
    "section": "CS Faculty Candidate",
    "text": "CS Faculty Candidate\n\nRazuan Hossain is here on Friday\nPlease attend a meet and greet at 3:15 in SBSC 112\nExtra Credit!"
  },
  {
    "objectID": "slides/lec-07.html#bar-chart",
    "href": "slides/lec-07.html#bar-chart",
    "title": "CISC482 - Lecture07",
    "section": "Bar Chart",
    "text": "Bar Chart\n\nA bar chart: groups on one axis, rectangles with heights that represent the number of samples."
  },
  {
    "objectID": "slides/lec-07.html#example-bar-chart",
    "href": "slides/lec-07.html#example-bar-chart",
    "title": "CISC482 - Lecture07",
    "section": "Example Bar Chart",
    "text": "Example Bar Chart\n\n\nCode\nspecies_count = df.groupby(['species'])['species'].count()\nax = sns.barplot(x=species_count.index.values, y=species_count.values)\nax.bar_label(ax.containers[0])\nax;"
  },
  {
    "objectID": "slides/lec-07.html#numerical-features",
    "href": "slides/lec-07.html#numerical-features",
    "title": "CISC482 - Lecture07",
    "section": "Numerical Features",
    "text": "Numerical Features\n\nSometimes we want visualize numerical features\nWe are interested in showing users the variation of this feature\nHistograms\nDensity Plots\nBox Plots"
  },
  {
    "objectID": "slides/lec-07.html#histogram-bar-chart",
    "href": "slides/lec-07.html#histogram-bar-chart",
    "title": "CISC482 - Lecture07",
    "section": "Histogram Bar Chart",
    "text": "Histogram Bar Chart"
  },
  {
    "objectID": "slides/lec-07.html#histogram-bar-chart-1",
    "href": "slides/lec-07.html#histogram-bar-chart-1",
    "title": "CISC482 - Lecture07",
    "section": "Histogram Bar Chart",
    "text": "Histogram Bar Chart\n\n\n\n\n\nDividing the numerical feature into small regions and then count the number of values in each region\nNotice - axis have labels!\nNotice - bar widths are small enough that you can see the distributions shape\n\n\n\n\nWhat do you notice about this distribution?\nWhat is (roughly) the most likely flipper length\n\n\n\n\n\n\nCode\nax = sns.histplot(data=df, x=\"flipper_length_mm\");"
  },
  {
    "objectID": "slides/lec-07.html#histogram-bar-horizontal-bar-chart",
    "href": "slides/lec-07.html#histogram-bar-horizontal-bar-chart",
    "title": "CISC482 - Lecture07",
    "section": "Histogram Bar Horizontal Bar Chart",
    "text": "Histogram Bar Horizontal Bar Chart\n\n\n\nSometimes its better to have the bar chart grow horizontal\n\n\n\n\nCode\nspecies_count = df.groupby(['species'])['species'].count()\nax = sns.barplot(data=df, y=\"island\", x=\"body_mass_g\", errorbar=None)\nax.bar_label(ax.containers[0]);"
  },
  {
    "objectID": "slides/lec-07.html#density-plot",
    "href": "slides/lec-07.html#density-plot",
    "title": "CISC482 - Lecture07",
    "section": "Density Plot",
    "text": "Density Plot\n\n\n\nA plot that approximates the density function of the distribution for the feature.\nDensity plots can be thought of as a smoothed histogram\n\n\n\n\nCode\nax = sns.kdeplot(data=df, x=\"body_mass_g\");"
  },
  {
    "objectID": "slides/lec-07.html#density-plot-with-histogram",
    "href": "slides/lec-07.html#density-plot-with-histogram",
    "title": "CISC482 - Lecture07",
    "section": "Density Plot with Histogram",
    "text": "Density Plot with Histogram\n\n\nCode\nax = sns.histplot(data=df, x=\"body_mass_g\", kde=True);"
  },
  {
    "objectID": "slides/lec-07.html#box-plot",
    "href": "slides/lec-07.html#box-plot",
    "title": "CISC482 - Lecture07",
    "section": "Box Plot",
    "text": "Box Plot\n\n\n\nA visual representation of the summary:\n\nminimum, maximum\nfirst quartile, median, third quartiles\noutliers\n\n\n\n\n\nCode\nax = sns.boxplot(data=df, x=\"body_mass_g\");"
  },
  {
    "objectID": "slides/lec-07.html#boxen-plot",
    "href": "slides/lec-07.html#boxen-plot",
    "title": "CISC482 - Lecture07",
    "section": "Boxen Plot",
    "text": "Boxen Plot\n\n\n\nPlots more quantiles\nProvides more information about the shape of the distribution, particularly in the tails.\n50%, 25%, 12.5%, 6.25%, 3.13%\n\n\n\n\nCode\nax = sns.boxenplot(data=df, x=\"body_mass_g\");"
  },
  {
    "objectID": "slides/lec-07.html#two-features",
    "href": "slides/lec-07.html#two-features",
    "title": "CISC482 - Lecture07",
    "section": "Two features",
    "text": "Two features\n\nWe visualized a single feature uses one axis to display the feature value and another axis to display the value’s frequency\nHowever, what if we want to communicate or investigate the relationship between two variables?\n\nScatterplot, line plots, etc!"
  },
  {
    "objectID": "slides/lec-07.html#example-scatter-plot-data",
    "href": "slides/lec-07.html#example-scatter-plot-data",
    "title": "CISC482 - Lecture07",
    "section": "Example Scatter Plot Data",
    "text": "Example Scatter Plot Data\n\ntips = sns.load_dataset(\"tips\")\ntips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4"
  },
  {
    "objectID": "slides/lec-07.html#example-scatter-plot",
    "href": "slides/lec-07.html#example-scatter-plot",
    "title": "CISC482 - Lecture07",
    "section": "Example Scatter Plot",
    "text": "Example Scatter Plot\n\n\n\nEvery point is a data point\nPoint out the best tips\nPoint out the worst tips\n\n\n\n\nCode\nsns.relplot(data=tips, x=\"total_bill\", y=\"tip\", aspect=1.5);"
  },
  {
    "objectID": "slides/lec-07.html#example-line-plot",
    "href": "slides/lec-07.html#example-line-plot",
    "title": "CISC482 - Lecture07",
    "section": "Example Line Plot",
    "text": "Example Line Plot\n\n\n\nCode\ntips = sns.load_dataset(\"tips\")\nsns.relplot(data=tips, x=\"total_bill\", y=\"tip\", aspect=1.5, kind='line');"
  },
  {
    "objectID": "slides/lec-07.html#combined-plot",
    "href": "slides/lec-07.html#combined-plot",
    "title": "CISC482 - Lecture07",
    "section": "Combined Plot",
    "text": "Combined Plot\n\nData points and linear regression model"
  },
  {
    "objectID": "slides/lec-07.html#looks-can-be-deceiving",
    "href": "slides/lec-07.html#looks-can-be-deceiving",
    "title": "CISC482 - Lecture07",
    "section": "Looks can be deceiving",
    "text": "Looks can be deceiving\n\nAlways show the points…"
  },
  {
    "objectID": "slides/lec-07.html#categorical-features-1",
    "href": "slides/lec-07.html#categorical-features-1",
    "title": "CISC482 - Lecture07",
    "section": "Categorical Features",
    "text": "Categorical Features\n\nSometimes we have a categorical feature and see the difference between two different sets\n\nCategory: Man, Woman. Feature: Height\nCategory: Friday, Saturday, Sunday. Feature: Avg. Tip\nCategory: Penguin Species. Feature: Body Mass"
  },
  {
    "objectID": "slides/lec-07.html#density-plot-with-histogram-species-as-hue",
    "href": "slides/lec-07.html#density-plot-with-histogram-species-as-hue",
    "title": "CISC482 - Lecture07",
    "section": "Density Plot with Histogram, Species as Hue",
    "text": "Density Plot with Histogram, Species as Hue\n\n\nCode\nax = sns.histplot(data=df, x=\"body_mass_g\", kde=True, hue='species');"
  },
  {
    "objectID": "slides/lec-07.html#bar-plot-sex-as-hue",
    "href": "slides/lec-07.html#bar-plot-sex-as-hue",
    "title": "CISC482 - Lecture07",
    "section": "Bar Plot, Sex as Hue",
    "text": "Bar Plot, Sex as Hue\n\n\nCode\n# Draw a nested barplot by species and sex\ng = sns.catplot(\n    data=df, kind=\"bar\", \n    x=\"species\", y=\"body_mass_g\", hue=\"sex\", \n    errorbar=None, alpha=0.6, dodge=False\n)"
  },
  {
    "objectID": "slides/lec-07.html#bar-plot-sex-as-hue-1",
    "href": "slides/lec-07.html#bar-plot-sex-as-hue-1",
    "title": "CISC482 - Lecture07",
    "section": "Bar Plot, Sex as Hue",
    "text": "Bar Plot, Sex as Hue\n\n\n\nWhat species and sex combination is the most prevalent?\nWhich species has the smallest numerical difference between sexes?\n\n\n\n\nCode\n# Draw a nested barplot by species and sex\ng = sns.catplot(\n    data=df, kind=\"bar\", \n    x=\"species\", y=\"body_mass_g\", hue=\"sex\", \n    errorbar=None, alpha=0.6\n)"
  },
  {
    "objectID": "slides/lec-07.html#strip-plot",
    "href": "slides/lec-07.html#strip-plot",
    "title": "CISC482 - Lecture07",
    "section": "Strip Plot",
    "text": "Strip Plot\n\n\nCode\ng = sns.catplot(\n    data=df, kind=\"strip\", \n    y=\"species\", x=\"bill_length_mm\", hue=\"sex\",  aspect=2, alpha=0.6\n)"
  },
  {
    "objectID": "slides/lec-07.html#swarm-plot",
    "href": "slides/lec-07.html#swarm-plot",
    "title": "CISC482 - Lecture07",
    "section": "Swarm Plot",
    "text": "Swarm Plot\n\nA swarm plot is a scatter plot with points jittered off the lines for the categorical feature so the points do not overlap.\nA swarm plot is useful for small datasets, but with an increasing number of points, the plots get too wide."
  },
  {
    "objectID": "slides/lec-07.html#swarm-plot-example",
    "href": "slides/lec-07.html#swarm-plot-example",
    "title": "CISC482 - Lecture07",
    "section": "Swarm Plot Example",
    "text": "Swarm Plot Example\n\n\nCode\ng = sns.swarmplot(\n    data=df, \n    y=\"species\", x=\"bill_length_mm\", hue='sex', alpha=0.6\n)"
  },
  {
    "objectID": "slides/lec-07.html#violin",
    "href": "slides/lec-07.html#violin",
    "title": "CISC482 - Lecture07",
    "section": "Violin",
    "text": "Violin\n\n\nCode\nsns.violinplot(data=df, x=\"bill_length_mm\", y=\"species\");"
  },
  {
    "objectID": "slides/lec-07.html#violin-explained",
    "href": "slides/lec-07.html#violin-explained",
    "title": "CISC482 - Lecture07",
    "section": "Violin Explained",
    "text": "Violin Explained"
  },
  {
    "objectID": "slides/lec-07.html#matplotlib",
    "href": "slides/lec-07.html#matplotlib",
    "title": "CISC482 - Lecture07",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nMatplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\nThe most popular graphic library (2D and 3D)\nOut of the box, plots are functional but don’t look too nice"
  },
  {
    "objectID": "slides/lec-07.html#matplotlib-example",
    "href": "slides/lec-07.html#matplotlib-example",
    "title": "CISC482 - Lecture07",
    "section": "Matplotlib Example",
    "text": "Matplotlib Example"
  },
  {
    "objectID": "slides/lec-07.html#seaborn",
    "href": "slides/lec-07.html#seaborn",
    "title": "CISC482 - Lecture07",
    "section": "Seaborn",
    "text": "Seaborn\n\nSeaborn is a Python data visualization library based on matplotlib\nNice and simple api that integrates very nicely with pandas\nJust pass it a data frame and call functions like\n\nhistplot\nscatterplot\nrelplot\nboxplot"
  },
  {
    "objectID": "slides/lec-07.html#seaborn-examples",
    "href": "slides/lec-07.html#seaborn-examples",
    "title": "CISC482 - Lecture07",
    "section": "Seaborn Examples",
    "text": "Seaborn Examples\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-14.html#schedule",
    "href": "slides/lec-14.html#schedule",
    "title": "CISC482 - Lecture14",
    "section": "Schedule",
    "text": "Schedule\n\nReading 6-1: Mar 08 @ 12PM, Wednesday\nReading 6-2: Mar 10 @ 12PM, Friday\nProposal: Mar 22, Wednesday\nHW5 - Mar 29 @ Midnight, Wednesday"
  },
  {
    "objectID": "slides/lec-14.html#today",
    "href": "slides/lec-14.html#today",
    "title": "CISC482 - Lecture14",
    "section": "Today",
    "text": "Today\n\nOverfit/Underfit\nBias/Variance Trade off\nRegression Metric\nBinary Classification Metrics"
  },
  {
    "objectID": "slides/lec-14.html#modelling",
    "href": "slides/lec-14.html#modelling",
    "title": "CISC482 - Lecture14",
    "section": "Modelling",
    "text": "Modelling\n\nWe approximate an output feature \\(y\\), using input features \\(X\\) with function \\(f\\) such that \\(\\hat{y} = f(X)\\)\n\nExample: Predicting penguin body mass by bill length\n\\(\\text{body mass} = \\hat{y} = mx + b\\)\n\nWe have to choose \\(f\\) and \\(X\\): simple linear model, polynomial model, multiple linear regression, logistic regression, etc.\nExample is \\(\\hat{y} = \\beta_0 + \\beta_1 x\\) or is \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\)"
  },
  {
    "objectID": "slides/lec-14.html#underfit",
    "href": "slides/lec-14.html#underfit",
    "title": "CISC482 - Lecture14",
    "section": "Underfit",
    "text": "Underfit\n\nUnderfit - model is too simple to fit the data well."
  },
  {
    "objectID": "slides/lec-14.html#underfit-problems",
    "href": "slides/lec-14.html#underfit-problems",
    "title": "CISC482 - Lecture14",
    "section": "Underfit Problems",
    "text": "Underfit Problems\n\nAn underfit model will miss the underlying trend\nWill score poorly in metrics"
  },
  {
    "objectID": "slides/lec-14.html#overfit",
    "href": "slides/lec-14.html#overfit",
    "title": "CISC482 - Lecture14",
    "section": "Overfit",
    "text": "Overfit\n\nOverfit - model is too complex to fit the data well."
  },
  {
    "objectID": "slides/lec-14.html#overfit-problems",
    "href": "slides/lec-14.html#overfit-problems",
    "title": "CISC482 - Lecture14",
    "section": "Overfit Problems",
    "text": "Overfit Problems\n\nFitting the data too closely\nIncorporating too much noise (meaningless variation)\nMisses the general trend of the data despite scoring well in some metrics"
  },
  {
    "objectID": "slides/lec-14.html#optimal",
    "href": "slides/lec-14.html#optimal",
    "title": "CISC482 - Lecture14",
    "section": "Optimal",
    "text": "Optimal\n\nThis model would be best fit with a quadratic model"
  },
  {
    "objectID": "slides/lec-14.html#note",
    "href": "slides/lec-14.html#note",
    "title": "CISC482 - Lecture14",
    "section": "Note",
    "text": "Note\n\n\n\n\n\n\nImportant\n\n\nA model that is overfit or underfit is a bad predictor of outcomes outside of the data set and should not be used. In the field of data science, models tend to be overfit, so model selection techniques focus on choosing the least complex model that captures the general trend."
  },
  {
    "objectID": "slides/lec-14.html#find-most-underfit-and-most-overfit",
    "href": "slides/lec-14.html#find-most-underfit-and-most-overfit",
    "title": "CISC482 - Lecture14",
    "section": "Find Most Underfit and Most Overfit",
    "text": "Find Most Underfit and Most Overfit"
  },
  {
    "objectID": "slides/lec-14.html#breaking-down-error",
    "href": "slides/lec-14.html#breaking-down-error",
    "title": "CISC482 - Lecture14",
    "section": "Breaking down Error",
    "text": "Breaking down Error\n\nThe total error of a model is how much the observed values differ from predicted values. Total error is broken down into three pieces:\n\nBias - model’s prediction differs from the observed values due to the assumptions built into the model.\nVariance - spread/variance of predictions\nIrreducible error - error inherent to the data (noise)"
  },
  {
    "objectID": "slides/lec-14.html#visual-explanation",
    "href": "slides/lec-14.html#visual-explanation",
    "title": "CISC482 - Lecture14",
    "section": "Visual Explanation",
    "text": "Visual Explanation"
  },
  {
    "objectID": "slides/lec-14.html#bias-variance-tradeoff",
    "href": "slides/lec-14.html#bias-variance-tradeoff",
    "title": "CISC482 - Lecture14",
    "section": "Bias-Variance Tradeoff",
    "text": "Bias-Variance Tradeoff\n\nChoosing a more complex model (more features, a more complicated mathematical expression, etc.) means the model’s predictions are closer to the observed sample values, which decreases the bias.\nHowever, doing so makes the model’s predictions more spread out to meet the observed values, increasing the variance.\nAn optimal model should be just complex enough to capture the general trend of the data (low bias) without incorporating too much of the noise from the sample (low variance)."
  },
  {
    "objectID": "slides/lec-14.html#visual-example",
    "href": "slides/lec-14.html#visual-example",
    "title": "CISC482 - Lecture14",
    "section": "Visual Example",
    "text": "Visual Example"
  },
  {
    "objectID": "slides/lec-14.html#problem-1",
    "href": "slides/lec-14.html#problem-1",
    "title": "CISC482 - Lecture14",
    "section": "Problem 1",
    "text": "Problem 1"
  },
  {
    "objectID": "slides/lec-14.html#problem-2",
    "href": "slides/lec-14.html#problem-2",
    "title": "CISC482 - Lecture14",
    "section": "Problem 2",
    "text": "Problem 2"
  },
  {
    "objectID": "slides/lec-14.html#dataset",
    "href": "slides/lec-14.html#dataset",
    "title": "CISC482 - Lecture14",
    "section": "Dataset",
    "text": "Dataset\n\nWe will be using the penguin dataset\n\n\n\nCode\nX = df['bill_length_mm'].values[:, np.newaxis]\ny = df['body_mass_g'].values\ndf.head()\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.10\n      18.70\n      181.00\n      3,750.00\n      male\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.50\n      17.40\n      186.00\n      3,800.00\n      female\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.30\n      18.00\n      195.00\n      3,250.00\n      female\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.70\n      19.30\n      193.00\n      3,450.00\n      female\n      2007\n    \n    \n      5\n      Adelie\n      Torgersen\n      39.30\n      20.60\n      190.00\n      3,650.00\n      male\n      2007"
  },
  {
    "objectID": "slides/lec-14.html#two-statistics",
    "href": "slides/lec-14.html#two-statistics",
    "title": "CISC482 - Lecture14",
    "section": "Two statistics",
    "text": "Two statistics\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = \\frac{\\text{variation explained by regression}}{\\text{total variation in the data}} = \\frac{\\sum (\\hat{y}_i - \\bar{y})^2}{\\sum (y_i - \\bar{y})^2}\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\n\nWhat indicates a good model fit? Higher or lower \\(R^2\\)? Higher or lower RMSE?"
  },
  {
    "objectID": "slides/lec-14.html#r-squared",
    "href": "slides/lec-14.html#r-squared",
    "title": "CISC482 - Lecture14",
    "section": "R-squared",
    "text": "R-squared\n\nRanges between 0 (terrible predictor) and 1 (perfect predictor), Unitless\nCalculate with model.score(X, y):\n\n\nmodel = LinearRegression()\nmodel.fit(X,y)\nr_squared = model.score(X,y)\nprint(f\"R^2 = {r_squared:.2f}\")\n\nR^2 = 0.35"
  },
  {
    "objectID": "slides/lec-14.html#graph",
    "href": "slides/lec-14.html#graph",
    "title": "CISC482 - Lecture14",
    "section": "Graph",
    "text": "Graph\n\nax = sns.scatterplot(x=X[:,0], y=y, color=\"black\")\nax.plot(X, model.predict(X), color=\"red\", linewidth=3)"
  },
  {
    "objectID": "slides/lec-14.html#r2-example",
    "href": "slides/lec-14.html#r2-example",
    "title": "CISC482 - Lecture14",
    "section": "\\(R^2\\) Example",
    "text": "\\(R^2\\) Example"
  },
  {
    "objectID": "slides/lec-14.html#interpreting-r-squared",
    "href": "slides/lec-14.html#interpreting-r-squared",
    "title": "CISC482 - Lecture14",
    "section": "Interpreting R-squared",
    "text": "Interpreting R-squared\n\nThe \\(R^2\\) of the model for predicting penguin mass from bill length is 25%. Which of the following is the correct interpretation of this value?\n\n\nBill Length correctly predicts 25% of penguin mass.\n25% of the variability in penguin mass can be explained by bill length.\n25% of the time penugin mass can be predicted by bill length."
  },
  {
    "objectID": "slides/lec-14.html#rmse",
    "href": "slides/lec-14.html#rmse",
    "title": "CISC482 - Lecture14",
    "section": "RMSE",
    "text": "RMSE\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the outcome variable\nCalculate with means_squared_error(y_true, y_pred):\n\nfrom sklearn import metrics\nrmse = metrics.mean_squared_error(y, model.predict(X))\nprint(f\"RMSE: {rmse:.2f}\")\n\nRMSE: 421823.22\n\n\nThe value of RMSE is not very meaningful on its own, but it’s useful for comparing across models.\nComparing a model that uses bill length for a predictor or using flipper length"
  },
  {
    "objectID": "slides/lec-14.html#rmse-example",
    "href": "slides/lec-14.html#rmse-example",
    "title": "CISC482 - Lecture14",
    "section": "RMSE Example",
    "text": "RMSE Example"
  },
  {
    "objectID": "slides/lec-14.html#truefalse-positivenegative",
    "href": "slides/lec-14.html#truefalse-positivenegative",
    "title": "CISC482 - Lecture14",
    "section": "True/False Positive/Negative",
    "text": "True/False Positive/Negative\n\nTrue Positive (TP) is an outcome that was correctly identified as positive\nTrue Negative (TN) is an outcome that was correctly identified as negative.\nFalse Positive (FP) is an outcome that was incorrectly identified as positive\nFalse Negative (TN) is an outcome that was incorrectly identified as negative"
  },
  {
    "objectID": "slides/lec-14.html#confustion-matrix",
    "href": "slides/lec-14.html#confustion-matrix",
    "title": "CISC482 - Lecture14",
    "section": "Confustion Matrix",
    "text": "Confustion Matrix\n\n\n\n\nPositive (predicted)\nNegative (predicted)\n\n\n\n\nPositive (actual)\n170\n21\n\n\nNegative (actual)\n1\n377"
  },
  {
    "objectID": "slides/lec-14.html#metrics",
    "href": "slides/lec-14.html#metrics",
    "title": "CISC482 - Lecture14",
    "section": "Metrics",
    "text": "Metrics\n\nAccuracy - useful\nPrecison - very useful\nRecall - very useful"
  },
  {
    "objectID": "slides/lec-14.html#accuracy",
    "href": "slides/lec-14.html#accuracy",
    "title": "CISC482 - Lecture14",
    "section": "Accuracy",
    "text": "Accuracy\n\n\nAccuracy: \\(\\frac{\\text{# Correctly Predicted}}{\\text{Total}}\\)\n\\(\\frac{TP + TN}{TP + TN + FP + FN}\\)"
  },
  {
    "objectID": "slides/lec-14.html#precision",
    "href": "slides/lec-14.html#precision",
    "title": "CISC482 - Lecture14",
    "section": "Precision",
    "text": "Precision\n\n\nTell how precise your prediction/is is\n\\(\\frac{TP}{TP + FP}\\)\nThe higher this number, the less False Positive you have\nMy research - Identifying an emegency landing location nearby. A precison gives confidence that it truly is safe to land at the locationt he model predicts."
  },
  {
    "objectID": "slides/lec-14.html#recall",
    "href": "slides/lec-14.html#recall",
    "title": "CISC482 - Lecture14",
    "section": "Recall",
    "text": "Recall\n\n\nthe proportion of positives that were correctly predicted\n\\(\\frac{TP}{TP + FN}\\)\nThe higher this number, the less False Negative you have.\nMy Research - A high recall means I found nearly all the rooftops in the city that you could land on."
  },
  {
    "objectID": "slides/lec-14.html#example-question",
    "href": "slides/lec-14.html#example-question",
    "title": "CISC482 - Lecture14",
    "section": "Example Question",
    "text": "Example Question\n\n\n\n\nPositive (predicted)\nNegative (predicted)\n\n\n\n\nPositive (actual)\n170\n21\n\n\nNegative (actual)\n1\n377\n\n\n\n\nWhat is the Accuracy, Precision, and Recall?"
  },
  {
    "objectID": "slides/lec-14.html#tradeoff",
    "href": "slides/lec-14.html#tradeoff",
    "title": "CISC482 - Lecture14",
    "section": "Tradeoff",
    "text": "Tradeoff\n\nIn logisitc regression you specify a threshold to use a prediciton. By deafult we use 0.5 or 50%. But that is arbitary and you move that threshold"
  },
  {
    "objectID": "slides/lec-14.html#low-threshold",
    "href": "slides/lec-14.html#low-threshold",
    "title": "CISC482 - Lecture14",
    "section": "Low Threshold",
    "text": "Low Threshold"
  },
  {
    "objectID": "slides/lec-14.html#high-threshold",
    "href": "slides/lec-14.html#high-threshold",
    "title": "CISC482 - Lecture14",
    "section": "High Threshold",
    "text": "High Threshold\n\n\n\n\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-12.html#schedule",
    "href": "slides/lec-12.html#schedule",
    "title": "CISC482 - Lecture12",
    "section": "Schedule",
    "text": "Schedule\n\nReading 6-1: Mar 08 @ 12PM, Wednesday\nTopic Ideas - Should be turned in! Will grade soon!\nHW4 - Mar 08 @ Midnight\nProposal: Mar 22, Wednesday"
  },
  {
    "objectID": "slides/lec-12.html#today",
    "href": "slides/lec-12.html#today",
    "title": "CISC482 - Lecture12",
    "section": "Today",
    "text": "Today\n\nReview Linear Regression\nLogistic Regression"
  },
  {
    "objectID": "slides/lec-12.html#what-we-learned",
    "href": "slides/lec-12.html#what-we-learned",
    "title": "CISC482 - Lecture12",
    "section": "What we learned",
    "text": "What we learned\n\n\nSimple Linear Regression\n\n\\(\\hat{y} = \\beta_0 + x + \\beta_1\\)\n\nSimple Polynomial Linear Regression\n\n\\(\\hat{y} = \\beta_0 + \\beta_1 x + ... + \\beta_k x^k\\)\n\nMultiple Linear Regression\n\n\\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + ... \\beta_k x_k\\)\n\nMultiple (Variable) Polynomial Regression\n\n\\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\beta_3 x_1 x_2 + \\beta_4 x_2 + \\beta_5 x_2^2\\)"
  },
  {
    "objectID": "slides/lec-12.html#regression-diagram",
    "href": "slides/lec-12.html#regression-diagram",
    "title": "CISC482 - Lecture12",
    "section": "Regression Diagram",
    "text": "Regression Diagram\n\n\n\n\nflowchart LR\n  A[Features] --> B{Single Feature}\n  B -- Yes --> C{Curvature}\n  C -- No --> E[Simple Regression]\n  C -- Yes --> D[Simple Polynomial <br> Regression]\n  B -- No --> F{Non-linear Correlation <br> Between Features}\n  F -- No --> G[Multiple Linear <br> Regression]\n  F -- Yes --> H[Polynomial Regression]"
  },
  {
    "objectID": "slides/lec-12.html#class-activity-1",
    "href": "slides/lec-12.html#class-activity-1",
    "title": "CISC482 - Lecture12",
    "section": "Class Activity",
    "text": "Class Activity\nDemo!"
  },
  {
    "objectID": "slides/lec-12.html#classification",
    "href": "slides/lec-12.html#classification",
    "title": "CISC482 - Lecture12",
    "section": "Classification",
    "text": "Classification\n\nWe are now going to be focusing on problems where we are interested in predicting the group or the class of something\nGive \\(X = {x_1, x_2, ..., x_k}\\) what is the class of this object.\n\nGiven the bill_length is 10 and bill_depth is 20 what is the species of this penguin?\nA person arrives at the emergency room with a set of symptoms. Which of the three medical conditions does the individual have?\n\nLets first focus where there are only 2 classes. Lets just call them (+) positive and (-) negative."
  },
  {
    "objectID": "slides/lec-12.html#example-classification",
    "href": "slides/lec-12.html#example-classification",
    "title": "CISC482 - Lecture12",
    "section": "Example Classification",
    "text": "Example Classification"
  },
  {
    "objectID": "slides/lec-12.html#linear-regression-for-classification",
    "href": "slides/lec-12.html#linear-regression-for-classification",
    "title": "CISC482 - Lecture12",
    "section": "Linear Regression for Classification",
    "text": "Linear Regression for Classification\n\nLinear Regression is generally not suitable for classification purposes\nHowever, you can use it to draw a line that whose value predicts the class\nE.g. if \\(\\hat{y} > 0.5 -> Positive\\)"
  },
  {
    "objectID": "slides/lec-12.html#lr-classification-okay",
    "href": "slides/lec-12.html#lr-classification-okay",
    "title": "CISC482 - Lecture12",
    "section": "LR Classification (Okay)",
    "text": "LR Classification (Okay)"
  },
  {
    "objectID": "slides/lec-12.html#lr-classification-bad",
    "href": "slides/lec-12.html#lr-classification-bad",
    "title": "CISC482 - Lecture12",
    "section": "LR Classification (BAD)",
    "text": "LR Classification (BAD)"
  },
  {
    "objectID": "slides/lec-12.html#lr-classification-really-bad",
    "href": "slides/lec-12.html#lr-classification-really-bad",
    "title": "CISC482 - Lecture12",
    "section": "LR Classification (Really BAD)",
    "text": "LR Classification (Really BAD)"
  },
  {
    "objectID": "slides/lec-12.html#logistic-regression",
    "href": "slides/lec-12.html#logistic-regression",
    "title": "CISC482 - Lecture12",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\n\n\n\nUse a specific exponential function\n\\(\\hat{y} = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}}\\)\nWhats the range of this function?\n\\(\\hat{p} = \\sigma(z)\\), where\n\n\\(z = \\beta_0 + \\beta_1 x\\)\n\\(\\sigma(z) = \\frac{e^{z}}{1 + e^{z}}\\)\n\\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\)"
  },
  {
    "objectID": "slides/lec-12.html#example",
    "href": "slides/lec-12.html#example",
    "title": "CISC482 - Lecture12",
    "section": "Example",
    "text": "Example\n\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\n\nlinear_model = LinearRegression()\nlogistic_model = LogisticRegression(C=1e5)\n\nlinear_model.fit(X, y)\nlogistic_model.fit(X, y)\n\nprint(f\"LINEAR MODEL: {linear_model.coef_[0]:.1f} * x + {linear_model.intercept_:.1f}\")\nprint(f\"LOGISTIC MODEL: sigmoid({logistic_model.coef_[0][0]:.1f} * x + {logistic_model.intercept_[0]:.1f})\");\n\nLINEAR MODEL: 0.1 * x + 0.4\nLOGISTIC MODEL: sigmoid(6.9 * x + -1.6)"
  },
  {
    "objectID": "slides/lec-12.html#visual",
    "href": "slides/lec-12.html#visual",
    "title": "CISC482 - Lecture12",
    "section": "Visual",
    "text": "Visual\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nWhat do you notice?"
  },
  {
    "objectID": "slides/lec-12.html#multivariable-classification",
    "href": "slides/lec-12.html#multivariable-classification",
    "title": "CISC482 - Lecture12",
    "section": "Multivariable Classification",
    "text": "Multivariable Classification"
  },
  {
    "objectID": "slides/lec-12.html#in-3d",
    "href": "slides/lec-12.html#in-3d",
    "title": "CISC482 - Lecture12",
    "section": "In 3D",
    "text": "In 3D"
  },
  {
    "objectID": "slides/lec-12.html#multivariable-logistic-regression",
    "href": "slides/lec-12.html#multivariable-logistic-regression",
    "title": "CISC482 - Lecture12",
    "section": "Multivariable Logistic Regression",
    "text": "Multivariable Logistic Regression\n\n\nCode\nlogistic_model = LogisticRegression(C=1e5)\nlogistic_model.fit(X, y)\n\nx_range = np.linspace(X[:, 0].min(), X[:, 0].max(), 20)\ny_range = np.linspace(X[:, 1].min(), X[:, 1].max(), 20)\nXX, YY = np.meshgrid(x_range, y_range)\nP = expit(XX* logistic_model.coef_[0][0] + YY * logistic_model.coef_[0][0] + logistic_model.intercept_)\n\n\nwith sns.plotting_context(\"talk\"):\n  fig = plt.figure(figsize = (10, 7))\n  ax = plt.axes(projection =\"3d\")\n  # ZZ = np.ones_like(XX) * 0.5 \n  # ax.plot_surface(XX, YY, ZZ,  **kwargs, zorder=1)\n  ax.scatter(X[:,0], X[:,1], y, c=y, cmap='jet', zorder=10, edgecolor='k')\n  ax.plot_surface(XX, YY, P, alpha=1.0, cmap='viridis', edgecolor='k');"
  },
  {
    "objectID": "slides/lec-12.html#multivariable-logistic-regression-1",
    "href": "slides/lec-12.html#multivariable-logistic-regression-1",
    "title": "CISC482 - Lecture12",
    "section": "Multivariable Logistic Regression",
    "text": "Multivariable Logistic Regression\n\n\nCode\nwith sns.plotting_context(\"talk\"):\n  fig = plt.figure(figsize = (10, 7))\n  ax = plt.axes(projection =\"3d\")\n  ZZ = np.ones_like(XX) * 0.5 \n  ax.plot_surface(XX, YY, ZZ,  zorder=1, edgecolor='k')\n  ax.plot_surface(XX, YY, P, alpha=1.0, cmap='viridis', edgecolor='k');"
  },
  {
    "objectID": "slides/lec-12.html#view-decision-boundary",
    "href": "slides/lec-12.html#view-decision-boundary",
    "title": "CISC482 - Lecture12",
    "section": "View Decision Boundary",
    "text": "View Decision Boundary\n\n\nCode\nfrom sklearn.inspection import DecisionBoundaryDisplay\ndisp = DecisionBoundaryDisplay.from_estimator(\n    logistic_model, X, response_method=\"predict\", cmap=plt.cm.viridis, alpha=0.5\n)\ndisp.ax_.scatter(X[:,0], X[:,1], c=y, cmap='viridis', edgecolor='k');\ndisp.ax_.set_xlabel(\"X\")\ndisp.ax_.set_ylabel(\"Y\")\n\n\nText(0, 0.5, 'Y')"
  },
  {
    "objectID": "slides/lec-12.html#loss-function",
    "href": "slides/lec-12.html#loss-function",
    "title": "CISC482 - Lecture12",
    "section": "Loss Function",
    "text": "Loss Function\n\n\nLets create a likelihood function \\(L\\) that is a function of our parameters \\(\\beta\\). We want to find parameters \\(\\beta\\) that make \\(L\\) as big as possible.\n\\(L(\\beta) = \\sum_{i=1}^n \\underbrace{y_i \\cdot \\sigma(\\beta \\; x_i)}_{y = 1} + \\underbrace{(1-y_i) \\cdot (1 - \\sigma(\\beta \\; x_i))}_{y = 0}\\)\nConvert to a loss function \\(J\\). We also take the logarithm. This ensures our cost function is convex.\n\\(J(\\beta) = -\\sum_{i=1}^n y_i \\cdot log(\\sigma(\\beta \\; x_i)) + (1-y_i) \\cdot log(\\sigma(\\beta \\; x_i))\\)\nThis does not have a closed form solution. AKA you can not just take derivative and solve the parameters \\(\\beta\\).\nWe have to use a numerical solver. For example, gradient descent."
  },
  {
    "objectID": "slides/lec-12.html#convex-vs-non-convex",
    "href": "slides/lec-12.html#convex-vs-non-convex",
    "title": "CISC482 - Lecture12",
    "section": "Convex vs Non Convex",
    "text": "Convex vs Non Convex"
  },
  {
    "objectID": "slides/lec-12.html#convex-function-soccer-ball",
    "href": "slides/lec-12.html#convex-function-soccer-ball",
    "title": "CISC482 - Lecture12",
    "section": "Convex Function, Soccer Ball",
    "text": "Convex Function, Soccer Ball"
  },
  {
    "objectID": "slides/lec-12.html#gradient-descent",
    "href": "slides/lec-12.html#gradient-descent",
    "title": "CISC482 - Lecture12",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-02.html#subscibre-to-zybook",
    "href": "slides/lec-02.html#subscibre-to-zybook",
    "title": "CISC482 - Lecture02",
    "section": "Subscibre to Zybook",
    "text": "Subscibre to Zybook\n\n\nBrightspace integration seems to be working now"
  },
  {
    "objectID": "slides/lec-02.html#due-dates",
    "href": "slides/lec-02.html#due-dates",
    "title": "CISC482 - Lecture02",
    "section": "Due Dates",
    "text": "Due Dates\n\nReading 1-1: Jan 22, Sunday\nHW1: Jan 25 @ Midnight, Wed\nReading 2-1: Jan 25 @ 12PM, Wed\nReading 2-2: Jan 27 @ 12PM, Friday\nHW2: Feb 1 @ Midnight, Wed"
  },
  {
    "objectID": "slides/lec-02.html#data-science",
    "href": "slides/lec-02.html#data-science",
    "title": "CISC482 - Lecture02",
    "section": "Data Science",
    "text": "Data Science\n\n\nData science is an interdisciplinary field focused on discovering patterns and describing relationships using data.\n\n\nData science uses techniques from computer science and statistics.\nData scientists use computers to write code and store, modify, and visualize large datasets.\nData scientists also build, test, and interpret models that describe real-life situations, then use models to make predictions for new data."
  },
  {
    "objectID": "slides/lec-02.html#ds-early-history",
    "href": "slides/lec-02.html#ds-early-history",
    "title": "CISC482 - Lecture02",
    "section": "DS early history",
    "text": "DS early history\n\n\nPeter Naur won the Turing Award\nAstronomer -> Computer Science -> Professor\nInventor of Algol Programming Language (PL)"
  },
  {
    "objectID": "slides/lec-02.html#ds-20th-century",
    "href": "slides/lec-02.html#ds-20th-century",
    "title": "CISC482 - Lecture02",
    "section": "DS 20th Century",
    "text": "DS 20th Century"
  },
  {
    "objectID": "slides/lec-02.html#statistics-and-computer-science",
    "href": "slides/lec-02.html#statistics-and-computer-science",
    "title": "CISC482 - Lecture02",
    "section": "Statistics and Computer Science",
    "text": "Statistics and Computer Science"
  },
  {
    "objectID": "slides/lec-02.html#focus-of-task",
    "href": "slides/lec-02.html#focus-of-task",
    "title": "CISC482 - Lecture02",
    "section": "Focus of Task",
    "text": "Focus of Task"
  },
  {
    "objectID": "slides/lec-02.html#statistics-and-machine-learning",
    "href": "slides/lec-02.html#statistics-and-machine-learning",
    "title": "CISC482 - Lecture02",
    "section": "Statistics and Machine Learning",
    "text": "Statistics and Machine Learning"
  },
  {
    "objectID": "slides/lec-02.html#where-are-we",
    "href": "slides/lec-02.html#where-are-we",
    "title": "CISC482 - Lecture02",
    "section": "Where are we?",
    "text": "Where are we?\n\n\nEqual Exploratory and Predictive\nLittle bit of statistics"
  },
  {
    "objectID": "slides/lec-02.html#learning-goals",
    "href": "slides/lec-02.html#learning-goals",
    "title": "CISC482 - Lecture02",
    "section": "Learning Goals",
    "text": "Learning Goals\n\nIdentify features and instances in a dataset\nThree V’s- volume, velocity, and variety"
  },
  {
    "objectID": "slides/lec-02.html#data-sets",
    "href": "slides/lec-02.html#data-sets",
    "title": "CISC482 - Lecture02",
    "section": "Data sets",
    "text": "Data sets\n\nA dataset is a collection of information. Consists of features and instances\nA feature, or variable, is a characteristic that can be measured or observed on an observational unit.\nAn instance, or observational units, is a tuple of features. Often called data points or observations."
  },
  {
    "objectID": "slides/lec-02.html#example-data-set",
    "href": "slides/lec-02.html#example-data-set",
    "title": "CISC482 - Lecture02",
    "section": "Example Data Set",
    "text": "Example Data Set\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      male\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      female\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      female\n      2007\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      female\n      2007\n    \n  \n\n\n\n\n\nROW is an instance.\nCOLUMN represents a different feature.\n\n\n\nResearchers at the Palmer Archipelago in the Antarctic collected data on three local penguin species: Adelie, Chinstrap, and Gentoo."
  },
  {
    "objectID": "slides/lec-02.html#volume-variety-velocity",
    "href": "slides/lec-02.html#volume-variety-velocity",
    "title": "CISC482 - Lecture02",
    "section": "Volume, Variety, Velocity",
    "text": "Volume, Variety, Velocity\n\nVolume - The amount of data being collected digitally is exponentially increasing.\nBillions of people are being digitally indexed and catalogued\nEstimate that 2.5 quintillion bytes of data is created each day\nWe now have the processing power where large data sets can now be processed\n\n\n\nBig data is really, really big. In 1986, the total estimated data in the world was 2.6 exabytes (EB).\nOne exabyte (EB) equals bytes, or 1 million TB. Most laptops come with 1 TB storage at most.\nBy 1993, the total estimated data in the world had grown to 15.8 EB.\nIn 2000, the total estimated data in the world had reached 54.5 EB.\nIn 2007, the total estimated data in the world was 295 EB.\nBy 2020, the total estimated data had increased to 6800 EB, or 6.8 PB - the equivalent of over 7 trillion laptop computers."
  },
  {
    "objectID": "slides/lec-02.html#volume-variety-velocity-1",
    "href": "slides/lec-02.html#volume-variety-velocity-1",
    "title": "CISC482 - Lecture02",
    "section": "Volume, Variety, Velocity",
    "text": "Volume, Variety, Velocity\n\nVariety - Data from a variety of difference sources are being collected and combined\nIts not just your name and your playlist.\n\nIts how long you listened\nHow long it took you swipe next\nYour search history on the subject\nYour bloody e-mails\nYour phones resolution, battery information, browser, time zone"
  },
  {
    "objectID": "slides/lec-02.html#volume-variety-velocity-2",
    "href": "slides/lec-02.html#volume-variety-velocity-2",
    "title": "CISC482 - Lecture02",
    "section": "Volume, Variety, Velocity",
    "text": "Volume, Variety, Velocity\n\nVelocity - Data is being created and ingested at a faster time\nThe search you just made was fed into an algorithm to give you an add within 10 seconds\nSensor Data - Your recorded heart rate was just noted and used to indicate the statistical likelihood of sending you an add now or later\nWith more up to date information, data scientist can make better predictions"
  },
  {
    "objectID": "slides/lec-02.html#reproducibility",
    "href": "slides/lec-02.html#reproducibility",
    "title": "CISC482 - Lecture02",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\nTwo data scientists are building models to classify brain tumors as benign or malignant.\nOne data scientist uses a programming language, such as Python, to write code to fit the model.\nAnother data scientist uses software instead of coding to fit the model.\nNew brain scans arrive. The data scientist who used coding re-runs the analysis -> a few minutes.\nSince the software uses a point and click interface, re-analyzing could take several hours."
  },
  {
    "objectID": "slides/lec-02.html#job-titles",
    "href": "slides/lec-02.html#job-titles",
    "title": "CISC482 - Lecture02",
    "section": "Job Titles",
    "text": "Job Titles\n\n\n\n\n\n\n\n\nTitle\nDescription\n\n\n\n\nData engineers\nData engineers specialize in data gathering and storage for production. Data engineers extract, transform, and load datasets for later analysis.\n\n\nData scientists\nData scientists gather data, transform data, and use models and algorithms to extract meaningful insights from datasets. Development\n\n\nData analysts\nData analysts work with industry experts to analyze datasets and create visualizations. Data analysts use some data science models, but tend to use data visualization and summary more than modeling.\n\n\nBusiness intelligence analysts\nBusiness intelligence analysts specialize in data related to financial and market transactions. Data analysts and business intelligence analysts are similar roles, but the term business intelligence is more common in business and finance.\n\n\nMachine learning engineers\nMachine learning engineers specialize in machine learning models instead of statistical models. Machine learning engineers often focus on the implementation and development of a model rather than selection and interpretation. Production"
  },
  {
    "objectID": "slides/lec-02.html#your-new-life",
    "href": "slides/lec-02.html#your-new-life",
    "title": "CISC482 - Lecture02",
    "section": "Your new life",
    "text": "Your new life\n\n\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\nStep 1: Gathering data\nIdentify available and relevant data; gather new data if needed.\n\n\nStep 2: Cleaning data\nReformat datasets, create new features, and address missing values.\n\n\nStep 3: Exploring data\nCreate data visualizations and calculate summary statistics to explore potential relationships in the dataset.\n\n\nStep 4: Modeling data\nUse modeling skills and content knowledge to fit and evaluate models, measure relationships, and make predictions.\n\n\nStep 5: Interpreting data\nDescribe and interpret conclusions from data through written reports and presentations."
  },
  {
    "objectID": "slides/lec-02.html#visualizing-the-5-steps",
    "href": "slides/lec-02.html#visualizing-the-5-steps",
    "title": "CISC482 - Lecture02",
    "section": "Visualizing the 5 Steps",
    "text": "Visualizing the 5 Steps"
  },
  {
    "objectID": "slides/lec-02.html#gathering-data",
    "href": "slides/lec-02.html#gathering-data",
    "title": "CISC482 - Lecture02",
    "section": "Gathering Data",
    "text": "Gathering Data\nGetting a dataset is easier then ever\n\nKaggle Datasets\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "slides/lec-02.html#example-dataset---palmer-penguins",
    "href": "slides/lec-02.html#example-dataset---palmer-penguins",
    "title": "CISC482 - Lecture02",
    "section": "Example Dataset - Palmer Penguins",
    "text": "Example Dataset - Palmer Penguins\n\nThe Palmer penguins dataset by Allison Horst, Alison Hill, and Kristen Gorman"
  },
  {
    "objectID": "slides/lec-02.html#the-researchers",
    "href": "slides/lec-02.html#the-researchers",
    "title": "CISC482 - Lecture02",
    "section": "The Researchers",
    "text": "The Researchers"
  },
  {
    "objectID": "slides/lec-02.html#cleaning-data---before",
    "href": "slides/lec-02.html#cleaning-data---before",
    "title": "CISC482 - Lecture02",
    "section": "Cleaning Data - Before",
    "text": "Cleaning Data - Before\n\n\n\n\n\n\n\n\n  \n    \n      \n      studyName\n      Sample Number\n      Species\n      Region\n      Island\n      Stage\n      Individual ID\n      Clutch Completion\n      Date Egg\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      Comments\n    \n  \n  \n    \n      0\n      PAL0708\n      1\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N1A1\n      Yes\n      2007-11-11\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n      NaN\n      NaN\n      Not enough blood for isotopes.\n    \n    \n      1\n      PAL0708\n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N1A2\n      Yes\n      2007-11-11\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      8.94956\n      -24.69454\n      NaN\n    \n    \n      2\n      PAL0708\n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A1\n      Yes\n      2007-11-16\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      8.36821\n      -25.33302\n      NaN\n    \n    \n      3\n      PAL0708\n      4\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A2\n      Yes\n      2007-11-16\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Adult not sampled.\n    \n    \n      4\n      PAL0708\n      5\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N3A1\n      Yes\n      2007-11-16\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      8.76651\n      -25.32426\n      NaN"
  },
  {
    "objectID": "slides/lec-02.html#important-features",
    "href": "slides/lec-02.html#important-features",
    "title": "CISC482 - Lecture02",
    "section": "Important Features",
    "text": "Important Features"
  },
  {
    "objectID": "slides/lec-02.html#cleaning-data---after",
    "href": "slides/lec-02.html#cleaning-data---after",
    "title": "CISC482 - Lecture02",
    "section": "Cleaning Data - After",
    "text": "Cleaning Data - After\n\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      male\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      female\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      female\n      2007\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      female\n      2007"
  },
  {
    "objectID": "slides/lec-02.html#exploring-data",
    "href": "slides/lec-02.html#exploring-data",
    "title": "CISC482 - Lecture02",
    "section": "Exploring Data",
    "text": "Exploring Data"
  },
  {
    "objectID": "slides/lec-02.html#modelling-data",
    "href": "slides/lec-02.html#modelling-data",
    "title": "CISC482 - Lecture02",
    "section": "Modelling Data",
    "text": "Modelling Data"
  },
  {
    "objectID": "slides/lec-02.html#interpreting-data",
    "href": "slides/lec-02.html#interpreting-data",
    "title": "CISC482 - Lecture02",
    "section": "Interpreting Data",
    "text": "Interpreting Data\n\nThere is a linear relationship between flipper length and body length\nGentoo penguins have significantly higher body length and body mass then Adelie or Chinstrap.\netc."
  },
  {
    "objectID": "slides/lec-02.html#big-takeaways",
    "href": "slides/lec-02.html#big-takeaways",
    "title": "CISC482 - Lecture02",
    "section": "Big Takeaways",
    "text": "Big Takeaways\n\nWhat is data science relationship with Statistics? Computer Science?\nThree V’s\nFive steps of data science"
  },
  {
    "objectID": "slides/lec-02.html#this-weeks-tasks",
    "href": "slides/lec-02.html#this-weeks-tasks",
    "title": "CISC482 - Lecture02",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nSign up for the Zybook\nRead the syllabus\nHW1 - Markdown"
  },
  {
    "objectID": "slides/lec-02.html#practice",
    "href": "slides/lec-02.html#practice",
    "title": "CISC482 - Lecture02",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 01 - Practice Markdown"
  },
  {
    "objectID": "slides/lec-02.html#hw1",
    "href": "slides/lec-02.html#hw1",
    "title": "CISC482 - Lecture02",
    "section": "HW1",
    "text": "HW1\nHW Link\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-05.html#schedule",
    "href": "slides/lec-05.html#schedule",
    "title": "CISC482 - Lecture05",
    "section": "Schedule",
    "text": "Schedule\n\nHW2: Feb 1 @ Midnight, Wednesday\nReading 3-1: Feb 3 @ 12PM, Friday\nHW3: Feb 15 @ Midnight, Wednesday\nExam 1: Feb 15 in Class"
  },
  {
    "objectID": "slides/lec-05.html#cs-faculty-candidate",
    "href": "slides/lec-05.html#cs-faculty-candidate",
    "title": "CISC482 - Lecture05",
    "section": "CS Faculty Candidate",
    "text": "CS Faculty Candidate\n\nBenz Tran is here Friday!\nPlease attend a meet and greet at 3:15 in SBSC 112\nExtra Credit!"
  },
  {
    "objectID": "slides/lec-05.html#master-degree",
    "href": "slides/lec-05.html#master-degree",
    "title": "CISC482 - Lecture05",
    "section": "Master Degree",
    "text": "Master Degree\n\nNortheastern University’s Roux Institute\nTuesday, February 21, 2023, noon to 2 p.m., in the Campus Union\nData Science, Computer Science, Project Management, etc.\n$25,000 scholarships for students who begin their Northeastern University master’s program at The Roux Institute in Fall 2023"
  },
  {
    "objectID": "slides/lec-05.html#main-ideas",
    "href": "slides/lec-05.html#main-ideas",
    "title": "CISC482 - Lecture05",
    "section": "Main Ideas",
    "text": "Main Ideas\n\nInferential statistics are methods that result in conclusions and estimates about the population based on a sample\nSeek to estimate the parameters that describe a populations distribution\n\nmean, std, etc.\n\nRemember, we collect data from a population, this creates a sample\nUsing that sample, we make inferences about the underlying population\nThe sample proportion of voters who plan to vote by mail is a statistic and estimates the parameter, or the population proportion, of all voters who plan to vote by mail.\n\n\n\n\n\n\n\nWarning\n\n\nWe will not go too deeply into this subject. We will only focus on the most important points."
  },
  {
    "objectID": "slides/lec-05.html#sampling",
    "href": "slides/lec-05.html#sampling",
    "title": "CISC482 - Lecture05",
    "section": "Sampling",
    "text": "Sampling\n\nBecause calculated statistics will vary from sample to sample due to natural sampling variability, statistics do not estimate parameters with 100% accuracy.\nThe overall behavior of a statistic from repeated sampling is described by a sampling distribution.\nThe sampling distribution of a statistic describes the statistic’s possible values and a measure of how likely the values are to occur."
  },
  {
    "objectID": "slides/lec-05.html#sampling-video",
    "href": "slides/lec-05.html#sampling-video",
    "title": "CISC482 - Lecture05",
    "section": "Sampling Video",
    "text": "Sampling Video\n\n\nMean of many means"
  },
  {
    "objectID": "slides/lec-05.html#central-limit-theorem",
    "href": "slides/lec-05.html#central-limit-theorem",
    "title": "CISC482 - Lecture05",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\n\n\n\n\n\nTip\n\n\nThe Central Limit Theorem (CLT) states that if random samples of size are drawn from a large population and is large enough, then the sampling distribution of the sample mean will follow approximately a normal distribution."
  },
  {
    "objectID": "slides/lec-05.html#hypothesis-test",
    "href": "slides/lec-05.html#hypothesis-test",
    "title": "CISC482 - Lecture05",
    "section": "Hypothesis Test",
    "text": "Hypothesis Test\n\nHypothesis Test - method for examining a claim, or hypothesis, about a population parameter.\nnull hypothesis, \\(H_0\\), by-chance, no-effect explanation\n\nmedicine has no effect\n\nalternative hypothesis, \\(H_a\\), explanation of an effect\n\nmedicine has a (positive) effect\n\np-value - or likelihood, of obtaining a statistic at least as extreme when \\(H_0\\) is true.\n\n\n\n\n\n\n\nDanger\n\n\nStatistics is widely and notoriously misunderstood. Even by experts. Including me."
  },
  {
    "objectID": "slides/lec-05.html#visualization",
    "href": "slides/lec-05.html#visualization",
    "title": "CISC482 - Lecture05",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "slides/lec-05.html#questions",
    "href": "slides/lec-05.html#questions",
    "title": "CISC482 - Lecture05",
    "section": "Questions",
    "text": "Questions\n\nA graph of the sampling distribution of the sample proportion of correct detections out of 37 trials when the null hypothesis is true is given below. Based on this graph, observing a sample proportion of 0.78 or greater is\nCan the dog detect cancer?\n\n\n\n\n\n\n\n\nDanger\n\n\nThis does not mean the dog detects cancer! This just means the dog is doing better than guessing! Maybe cancer patients eat PB sandwiches and thats what the dog is smelling!"
  },
  {
    "objectID": "slides/lec-05.html#type-1-and-type-2-errors",
    "href": "slides/lec-05.html#type-1-and-type-2-errors",
    "title": "CISC482 - Lecture05",
    "section": "Type 1 and Type 2 Errors",
    "text": "Type 1 and Type 2 Errors\n\nType 1 Error - is rejecting the null hypothesis in favor of the alternative when in reality the null hypothesis is true.\n\nFalse Positive\n\nType 2 Error - is failing to reject (accepting) the null hypothesis when in reality the alternative hypothesis is true.\n\nFalse Negative\n\n\n\n\n\n\n\n\nTip\n\n\nBinary Outcomes, True or False, 1 or 0\nFalse-Positive = Incorrectly Predict a Positive Outcome\n\\[\n\\underbrace{\\textbf{False}}_{\\textbf{Correct or Incorrect}}-\\underbrace{\\textbf{Positive}}_{\\textbf{Your Prediction}}\n\\]"
  },
  {
    "objectID": "slides/lec-05.html#table",
    "href": "slides/lec-05.html#table",
    "title": "CISC482 - Lecture05",
    "section": "Table",
    "text": "Table\n\n\n\n\nActual Positive\nActual Negative\n\n\n\n\nPredict Positive\nTP\nFP, Type I\n\n\nPredict Negative\nFN, Type II\nTN"
  },
  {
    "objectID": "slides/lec-05.html#confidence-intervals",
    "href": "slides/lec-05.html#confidence-intervals",
    "title": "CISC482 - Lecture05",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nSometimes you want to estimate the value of a population parameter (e.g., the mean)\nConfidence Interval provides an interval of possible values for the parameter being estimated\n\nestimate +- margin of error\n\nMargin of error includes\n\nthe standard error, or measure of sampling variability\nConfidence level, or measure of interval reliability. Usually set at 95%."
  },
  {
    "objectID": "slides/lec-05.html#example",
    "href": "slides/lec-05.html#example",
    "title": "CISC482 - Lecture05",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/lec-05.html#standard-deviation-of-sampling-distribution",
    "href": "slides/lec-05.html#standard-deviation-of-sampling-distribution",
    "title": "CISC482 - Lecture05",
    "section": "Standard Deviation of Sampling Distribution",
    "text": "Standard Deviation of Sampling Distribution\n\nWe don’t usually have the standard deviation of sampling distribution.\nEstimate with the Standard Error\n\\(SD_{\\hat{p}} = SD_{\\bar{x}} = \\sigma_{\\bar{x}} = SEM\\)\n\\(SD_{\\bar{p}} = \\frac{\\sigma_x}{\\sqrt{N}}\\)\n\n\\(\\sigma_x\\) - This is the standard deviation of your samples\n\\(N\\) - How many samples you took\n\n\n\n\n\n\n\n\nTip\n\n\nUse standard error when estimating means."
  },
  {
    "objectID": "slides/lec-05.html#confirming-reported-statistic",
    "href": "slides/lec-05.html#confirming-reported-statistic",
    "title": "CISC482 - Lecture05",
    "section": "Confirming reported statistic",
    "text": "Confirming reported statistic\n\n\nGiven a statistic about a population, \\(\\hat{\\pi}\\). Mean radon levels of houses in Iowa.\nYou gather samples that are IID. Independent and identically distributed\nCompute the mean and standard deviation from your sample: \\(\\hat{p}, \\hat{\\sigma}\\)\n\\(H_0\\): The true population mean is \\(\\hat{\\pi}\\). \\(\\pi = \\hat{\\pi}\\)\n\\(H_a\\): The true population mean is not \\(\\hat{\\pi}\\). \\(\\pi \\neq \\hat{\\pi}\\)"
  },
  {
    "objectID": "slides/lec-05.html#procedure",
    "href": "slides/lec-05.html#procedure",
    "title": "CISC482 - Lecture05",
    "section": "Procedure",
    "text": "Procedure"
  },
  {
    "objectID": "slides/lec-05.html#z-table",
    "href": "slides/lec-05.html#z-table",
    "title": "CISC482 - Lecture05",
    "section": "Z-table",
    "text": "Z-table\nZ Table\n\n\n\n\n\n\n\nDanger\n\n\nWhat if we didn’t gather that many samples, e.g., \\(< 30\\)? Then our sampling distribution follows a t-distribution."
  },
  {
    "objectID": "slides/lec-05.html#t-vs-normal-distribution",
    "href": "slides/lec-05.html#t-vs-normal-distribution",
    "title": "CISC482 - Lecture05",
    "section": "T vs Normal Distribution",
    "text": "T vs Normal Distribution"
  },
  {
    "objectID": "slides/lec-05.html#t-table",
    "href": "slides/lec-05.html#t-table",
    "title": "CISC482 - Lecture05",
    "section": "T-table",
    "text": "T-table\nLink"
  },
  {
    "objectID": "slides/lec-05.html#highlights",
    "href": "slides/lec-05.html#highlights",
    "title": "CISC482 - Lecture05",
    "section": "Highlights",
    "text": "Highlights\n\nInferential statistics are methods that result in conclusions and estimates about the population based on a sample\nHypothesis Testing - create a null hypothesis, gather data, compute sample statistics, compute z-score and generate p-value.\nConfidence Interval - sample data, compute sample statistics, use confidence multiplier (z-value) and standard deviation of samples to compute margin of error"
  },
  {
    "objectID": "slides/lec-05.html#whats-next",
    "href": "slides/lec-05.html#whats-next",
    "title": "CISC482 - Lecture05",
    "section": "Whats next?",
    "text": "Whats next?\n\nStart playing more with data!\nWill be using the software pandas to help analyze the data\nCleaning data\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-09.html#schedule",
    "href": "slides/lec-09.html#schedule",
    "title": "CISC482 - Lecture09",
    "section": "Schedule",
    "text": "Schedule\n\nReading 5-1: Feb 22 @ 12PM, Wednesday\nReading 5-2: Feb 24 @ 12PM, Friday\nTopic Ideas - Feb 22 @ Midnight"
  },
  {
    "objectID": "slides/lec-09.html#today",
    "href": "slides/lec-09.html#today",
    "title": "CISC482 - Lecture09",
    "section": "Today",
    "text": "Today\n\nReview Exam\nReview Topic Ideas\nMore Exploratory Data Analysis"
  },
  {
    "objectID": "slides/lec-09.html#most-missed-questions",
    "href": "slides/lec-09.html#most-missed-questions",
    "title": "CISC482 - Lecture09",
    "section": "Most Missed Questions",
    "text": "Most Missed Questions\n\nStudent spending at bookstore is normally distributed with a mean of $130 and a standard deviation of $30. Approximately what percentage of students spend less than $100 a month. Options: - 16, 20, 33, 50\nSpringfield College wants to give gift cards to the top 3% of spenders. What should be monthly spending cutoff to determine which students get gift cards?\n\n130, 160, 186, 220\n\nHypothesis Testing, p-value of 0.01, using 95% confidence when making a decison to reject or accept null hypothesis."
  },
  {
    "objectID": "slides/lec-09.html#normal-distribution",
    "href": "slides/lec-09.html#normal-distribution",
    "title": "CISC482 - Lecture09",
    "section": "Normal Distribution",
    "text": "Normal Distribution"
  },
  {
    "objectID": "slides/lec-09.html#normal-distribution-solution",
    "href": "slides/lec-09.html#normal-distribution-solution",
    "title": "CISC482 - Lecture09",
    "section": "Normal Distribution Solution",
    "text": "Normal Distribution Solution\n\n50% of students spend more than 130. 34% of students spend between 100 and 130. Thefore 50+34=84% students spend more than 100. Thefore 100-84=16% students spend less than 100.\n50% of students spend at least 130. Roughly 34+14=48% of students spend between 130 and 190 dollars. Thefore 50+48=98% students spend less than 190. Thefore the top 2% spends 190 or more. If we want the top 3% it will be must a little less. Looking at the options 186 is the best one."
  },
  {
    "objectID": "slides/lec-09.html#hypothesis-testing-solution",
    "href": "slides/lec-09.html#hypothesis-testing-solution",
    "title": "CISC482 - Lecture09",
    "section": "Hypothesis Testing Solution",
    "text": "Hypothesis Testing Solution\n\nReject null hypothesis when p-value is less than 0.05 and accept the alternative hypothesis."
  },
  {
    "objectID": "slides/lec-09.html#purpose",
    "href": "slides/lec-09.html#purpose",
    "title": "CISC482 - Lecture09",
    "section": "Purpose",
    "text": "Purpose\n\nFind 2-3 datasets that you are interested and are connected to your core signature assignments\nVerify the data is suitable for analysis\nPractice writing concisely and clearly about complex topics"
  },
  {
    "objectID": "slides/lec-09.html#requirements",
    "href": "slides/lec-09.html#requirements",
    "title": "CISC482 - Lecture09",
    "section": "Requirements",
    "text": "Requirements\n\nData Requirements\nPaper Requirements"
  },
  {
    "objectID": "slides/lec-09.html#data-requirements",
    "href": "slides/lec-09.html#data-requirements",
    "title": "CISC482 - Lecture09",
    "section": "Data Requirements",
    "text": "Data Requirements\n\nAt least 100 observations\nAt least 8 columns\nAt least 6 of the columns must be useful and unique predictor variables.\nAt least one variable that can be identified as a reasonable response variable\n\nThe response variable can be quantitative or categorical.\n\nObservations should reasonably meet the independence condition."
  },
  {
    "objectID": "slides/lec-09.html#paper-requirements",
    "href": "slides/lec-09.html#paper-requirements",
    "title": "CISC482 - Lecture09",
    "section": "Paper Requirements",
    "text": "Paper Requirements\n\nIntroduction\nResearch Question\nGlimpse of Data"
  },
  {
    "objectID": "slides/lec-09.html#introduction-section",
    "href": "slides/lec-09.html#introduction-section",
    "title": "CISC482 - Lecture09",
    "section": "Introduction Section",
    "text": "Introduction Section\n\nState source of data\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nDescribe the observations and the general characteristics being measured in the data.\nDescribe how the data set connect to your Core Studies."
  },
  {
    "objectID": "slides/lec-09.html#research-question",
    "href": "slides/lec-09.html#research-question",
    "title": "CISC482 - Lecture09",
    "section": "Research Question",
    "text": "Research Question\n\nDescribe a research question you’re interested in answering using this data\nCan you accurately predict whether a person will survive in the titanic data set? What features would be most important to make that prediction?"
  },
  {
    "objectID": "slides/lec-09.html#glimpse-of-data",
    "href": "slides/lec-09.html#glimpse-of-data",
    "title": "CISC482 - Lecture09",
    "section": "Glimpse of Data",
    "text": "Glimpse of Data\n\nPlease print out the results of the info() function of the dataframe\nAlso print out the first few rows of data head()"
  },
  {
    "objectID": "slides/lec-09.html#example-template",
    "href": "slides/lec-09.html#example-template",
    "title": "CISC482 - Lecture09",
    "section": "Example Template",
    "text": "Example Template\n\nBrightspace assignment\nLink to template to follow\nCopy and put in your shared google drive folder\nPrint PDF and submit to brightspace"
  },
  {
    "objectID": "slides/lec-09.html#steps",
    "href": "slides/lec-09.html#steps",
    "title": "CISC482 - Lecture09",
    "section": "Steps",
    "text": "Steps\n\nUnderstand the Data\n\nSize of the dataset (rows,cols), features (categorical, numerical).\n\nIdentify Relationships between features\n\nDirection and strength of correlation\n\nDescribe the shape of the data\n\nSymmetric, Skewed\n\nDetect outliers and missing values\n\nBox an Whisker!"
  },
  {
    "objectID": "slides/lec-09.html#understand-the-data",
    "href": "slides/lec-09.html#understand-the-data",
    "title": "CISC482 - Lecture09",
    "section": "Understand the Data",
    "text": "Understand the Data\n\nNumber of Rows, Columns?\nWhat features are categorical vs numeric?\nAny missing data?"
  },
  {
    "objectID": "slides/lec-09.html#example-data",
    "href": "slides/lec-09.html#example-data",
    "title": "CISC482 - Lecture09",
    "section": "Example Data",
    "text": "Example Data\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\nNone\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.10\n      18.70\n      181.00\n      3,750.00\n      male\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.50\n      17.40\n      186.00\n      3,800.00\n      female\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.30\n      18.00\n      195.00\n      3,250.00\n      female\n      2007\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.70\n      19.30\n      193.00\n      3,450.00\n      female\n      2007"
  },
  {
    "objectID": "slides/lec-09.html#relationship-1",
    "href": "slides/lec-09.html#relationship-1",
    "title": "CISC482 - Lecture09",
    "section": "Relationship 1",
    "text": "Relationship 1"
  },
  {
    "objectID": "slides/lec-09.html#relationship-2",
    "href": "slides/lec-09.html#relationship-2",
    "title": "CISC482 - Lecture09",
    "section": "Relationship 2",
    "text": "Relationship 2"
  },
  {
    "objectID": "slides/lec-09.html#relationship-3",
    "href": "slides/lec-09.html#relationship-3",
    "title": "CISC482 - Lecture09",
    "section": "Relationship 3",
    "text": "Relationship 3"
  },
  {
    "objectID": "slides/lec-09.html#quantifying-the-relationship",
    "href": "slides/lec-09.html#quantifying-the-relationship",
    "title": "CISC482 - Lecture09",
    "section": "Quantifying the Relationship",
    "text": "Quantifying the Relationship\n\nCovariance - measure of the joint variability of two random variables\nThe sign of the covariance, therefore, shows whether it is positive or negative relationship\n\\(Cov(X,Y)= \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{n}\\)\nThe magnitude doesn’t tell you much….we need a way to normalize it….Correlation to the rescue!"
  },
  {
    "objectID": "slides/lec-09.html#correlation",
    "href": "slides/lec-09.html#correlation",
    "title": "CISC482 - Lecture09",
    "section": "Correlation",
    "text": "Correlation\n\nA metric between -1 and +1\n\\(r(X,Y)= \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\bar{x})^2 \\cdot \\sum_{i=1}^n(y_i - \\bar{y})}}\\)\n\\(r(X,Y)= \\frac{Cov(X,Y)}{\\sigma_x \\cdot \\sigma_y}\\)"
  },
  {
    "objectID": "slides/lec-09.html#example-data-1",
    "href": "slides/lec-09.html#example-data-1",
    "title": "CISC482 - Lecture09",
    "section": "Example Data",
    "text": "Example Data\n\n\ndata = np.array([\n  [1, 2,   -2,     3],\n  [2, 4,   -4,     3],\n  [3, 3.5, -3.5,   3],\n  [4, 7.5, -7.5,   3],\n  [5, 10.2, -10.2, 3],\n  [6, 12.1, -12.1, 3],\n])\ncov = np.cov(data, rowvar=False)\nprint('Cov:', np.array2string(cov, prefix='Cov: ', formatter={'float_kind':lambda x: f\"{x:5.1f}\"}))\nprint(np.var(data[:, 0], ddof=1))\nprint(np.var(data[:, 1], ddof=1))\n\n\nCov: [[  3.5   7.3  -7.3   0.0]\n      [  7.3  16.3 -16.3   0.0]\n      [ -7.3 -16.3  16.3   0.0]\n      [  0.0   0.0   0.0   0.0]]\n3.5\n16.307"
  },
  {
    "objectID": "slides/lec-09.html#example-correlation-graph",
    "href": "slides/lec-09.html#example-correlation-graph",
    "title": "CISC482 - Lecture09",
    "section": "Example Correlation Graph",
    "text": "Example Correlation Graph\n\n\ncorr = np.corrcoef(data, rowvar=False)\ndataplot = sns.heatmap(corr, cmap=\"vlag\", annot=True)"
  },
  {
    "objectID": "slides/lec-09.html#secret-weapon",
    "href": "slides/lec-09.html#secret-weapon",
    "title": "CISC482 - Lecture09",
    "section": "Secret Weapon",
    "text": "Secret Weapon\n\nNow its time to show you my secret weapon\nDont tell anyone : )\nWhat I am about to show you single handedly landed me an offer to work at a big company in California\nNow for the story"
  },
  {
    "objectID": "slides/lec-09.html#background",
    "href": "slides/lec-09.html#background",
    "title": "CISC482 - Lecture09",
    "section": "Background",
    "text": "Background\n\nMy job was to predict where on the airport runway the airplane was using cameras\nSpecifally your lateral position on the runway"
  },
  {
    "objectID": "slides/lec-09.html#the-story-continued",
    "href": "slides/lec-09.html#the-story-continued",
    "title": "CISC482 - Lecture09",
    "section": "The Story (Continued)",
    "text": "The Story (Continued)\n\n\nI created a model that predicted cross-track position.\n\n\\(\\hat{CT} = f(\\text{FlightState}) = f(\\theta, \\psi, \\phi, \\text{image, etc.})\\)\n\nWe had the true CT position (from GPS) to compare my model against. \\(Error = \\hat{CT} - CT\\)\nIt worked great most of the time!\nHowever, we kept getting really large errors sometimes\nNo obvious pattern?\nWHY!?!?!"
  },
  {
    "objectID": "slides/lec-09.html#data",
    "href": "slides/lec-09.html#data",
    "title": "CISC482 - Lecture09",
    "section": "Data",
    "text": "Data\n\n\n\n\n\n\n  \n    \n      \n      ct_error\n      roll\n      pitch\n      yaw\n      downtracks\n      crosstracks\n    \n  \n  \n    \n      0\n      1.63\n      7.99\n      2.55\n      3.91\n      0.00\n      0.00\n    \n    \n      1\n      3.33\n      2.93\n      -2.10\n      3.89\n      4.02\n      1.10\n    \n    \n      2\n      2.43\n      0.12\n      -0.72\n      -0.41\n      8.03\n      2.20\n    \n    \n      3\n      3.24\n      -1.19\n      -2.21\n      -15.68\n      12.05\n      3.30\n    \n    \n      4\n      3.16\n      4.12\n      -3.75\n      -5.25\n      16.06\n      4.39"
  },
  {
    "objectID": "slides/lec-09.html#pair-plot",
    "href": "slides/lec-09.html#pair-plot",
    "title": "CISC482 - Lecture09",
    "section": "Pair Plot",
    "text": "Pair Plot\nsns.pairplot(df_bad)"
  },
  {
    "objectID": "slides/lec-09.html#more-data",
    "href": "slides/lec-09.html#more-data",
    "title": "CISC482 - Lecture09",
    "section": "More Data!",
    "text": "More Data!\n\n\n\n\n\n\n  \n    \n      \n      ct_error\n      roll\n      pitch\n      yaw\n      downtracks\n      crosstracks\n      alt\n    \n  \n  \n    \n      0\n      1.63\n      7.99\n      2.55\n      3.91\n      0.00\n      0.00\n      203.27\n    \n    \n      1\n      3.33\n      2.93\n      -2.10\n      3.89\n      4.02\n      1.10\n      206.84\n    \n    \n      2\n      2.43\n      0.12\n      -0.72\n      -0.41\n      8.03\n      2.20\n      205.51\n    \n    \n      3\n      3.24\n      -1.19\n      -2.21\n      -15.68\n      12.05\n      3.30\n      207.36\n    \n    \n      4\n      3.16\n      4.12\n      -3.75\n      -5.25\n      16.06\n      4.39\n      207.70"
  },
  {
    "objectID": "slides/lec-09.html#the-error",
    "href": "slides/lec-09.html#the-error",
    "title": "CISC482 - Lecture09",
    "section": "The Error",
    "text": "The Error\n\nLong story short, the GPS altitude was broken!\nIt was reporting that the airpane was off the ground!\nMy algorithm took into account your height off the ground.\nAt first, my bosses would not beleive me! It was a $10,000 GPS!\nBut the correlation plots and all my subsequent research convinced them"
  },
  {
    "objectID": "slides/lec-09.html#the-true-error",
    "href": "slides/lec-09.html#the-true-error",
    "title": "CISC482 - Lecture09",
    "section": "The True Error",
    "text": "The True Error\n\nSomeone forgot to renew the subscription service for the High Precision GPS!"
  },
  {
    "objectID": "slides/lec-09.html#key-workflow-and-graphs",
    "href": "slides/lec-09.html#key-workflow-and-graphs",
    "title": "CISC482 - Lecture09",
    "section": "Key Workflow and Graphs",
    "text": "Key Workflow and Graphs\n\nDescriptive Statisitcs\n\nMeans, quartiles, etc. for each feature\n\nHistogram of any intresting features\nShape of Data\nMissing Data\nFind relationship (Correlation)"
  },
  {
    "objectID": "slides/lec-09.html#class-activity-1",
    "href": "slides/lec-09.html#class-activity-1",
    "title": "CISC482 - Lecture09",
    "section": "Class Activity",
    "text": "Class Activity\nWork on your Topic Idea!\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-10.html#schedule",
    "href": "slides/lec-10.html#schedule",
    "title": "CISC482 - Lecture10",
    "section": "Schedule",
    "text": "Schedule\n\nTopic Ideas - Feb 22 @ Midnight\nReading 5-1: Feb 22 @ 12PM, Wednesday\nReading 5-2: Feb 24 @ 12PM, Friday\nReading 5-3: Mar 01 @ 12PM, Wednesday"
  },
  {
    "objectID": "slides/lec-10.html#today",
    "href": "slides/lec-10.html#today",
    "title": "CISC482 - Lecture10",
    "section": "Today",
    "text": "Today\n\nIntroduction to Regression\nReview Topic Ideas\nMore Exploratory Data Analysis"
  },
  {
    "objectID": "slides/lec-10.html#input-and-output",
    "href": "slides/lec-10.html#input-and-output",
    "title": "CISC482 - Lecture10",
    "section": "Input and Output",
    "text": "Input and Output\n\nAn input feature takes values without being impacted by any other features.\nAn output feature has values that vary in response to variation in some other feature(s).\n\nWe often called this the response variable\n\nIn an experiment, input features are often controlled by researchters, and output features are observed\nWe often visualize these with scatter plots"
  },
  {
    "objectID": "slides/lec-10.html#example-data",
    "href": "slides/lec-10.html#example-data",
    "title": "CISC482 - Lecture10",
    "section": "Example Data",
    "text": "Example Data\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.10\n      18.70\n      181.00\n      3,750.00\n      male\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.50\n      17.40\n      186.00\n      3,800.00\n      female\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.30\n      18.00\n      195.00\n      3,250.00\n      female\n      2007\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.70\n      19.30\n      193.00\n      3,450.00\n      female\n      2007"
  },
  {
    "objectID": "slides/lec-10.html#scatter-plot",
    "href": "slides/lec-10.html#scatter-plot",
    "title": "CISC482 - Lecture10",
    "section": "Scatter Plot",
    "text": "Scatter Plot\n\n\nCorrelation: 0.60"
  },
  {
    "objectID": "slides/lec-10.html#describing",
    "href": "slides/lec-10.html#describing",
    "title": "CISC482 - Lecture10",
    "section": "Describing",
    "text": "Describing\n\nThe direction: positive if larger values of one feature correspond to larger values of the other feature.\nThe form: linear pattern or a nonlinear pattern. Sometimes two features may not have an obvious form.\nThe strength: how closely the observations in a scatter plot follow the form’s pattern."
  },
  {
    "objectID": "slides/lec-10.html#questions",
    "href": "slides/lec-10.html#questions",
    "title": "CISC482 - Lecture10",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "slides/lec-10.html#correlation",
    "href": "slides/lec-10.html#correlation",
    "title": "CISC482 - Lecture10",
    "section": "Correlation",
    "text": "Correlation\n\nCorrelation is a statistical measure that expresses the extent to which two variables are linearly related\nThey change together at a constant rate\nIt’s a common tool for describing simple relationships without making a statement about cause and effect.\nRange from -1 to 0 to +1"
  },
  {
    "objectID": "slides/lec-10.html#regression-model",
    "href": "slides/lec-10.html#regression-model",
    "title": "CISC482 - Lecture10",
    "section": "Regression Model",
    "text": "Regression Model\n\nA model for an output feature \\(y\\) using input feature(s) \\(X\\) is a function \\(f(X)\\) that predicts an expected value \\(\\hat{y}\\) for a given value of \\(X\\).and\n\\(\\hat{y} = f(X)\\)\nA regression model is one that has a numerical output feature and input features."
  },
  {
    "objectID": "slides/lec-10.html#regression-example",
    "href": "slides/lec-10.html#regression-example",
    "title": "CISC482 - Lecture10",
    "section": "Regression Example",
    "text": "Regression Example\n\nWhat is the error of our model (Residual)"
  },
  {
    "objectID": "slides/lec-10.html#main-equation",
    "href": "slides/lec-10.html#main-equation",
    "title": "CISC482 - Lecture10",
    "section": "Main Equation",
    "text": "Main Equation\n\n\nSet of data: \\(\\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}\\)\n\nx: input, y: output\n\nModel: \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\epsilon\\)\n\n\\(\\hat{y}\\) = prediction\n\\(\\beta_0\\) = y-intercept\n\\(\\beta_1\\) = slope\n\\(\\epsilon = error\\)"
  },
  {
    "objectID": "slides/lec-10.html#visual-explanation",
    "href": "slides/lec-10.html#visual-explanation",
    "title": "CISC482 - Lecture10",
    "section": "Visual Explanation",
    "text": "Visual Explanation\n\n\n\n\n\n\n\nTip\n\n\nHow can we formalize what we are optimizing for?"
  },
  {
    "objectID": "slides/lec-10.html#formulation",
    "href": "slides/lec-10.html#formulation",
    "title": "CISC482 - Lecture10",
    "section": "Formulation",
    "text": "Formulation\n\n\n\nWe want to find the \\(\\beta_0\\) and \\(\\beta_1\\) parameters that reduce the combined error.\nA loss function that takes as input our parameters and whose output is our model error.\n\\(f(\\beta_0, \\beta_1) = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = \\sum\\limits_{i=1}^{n}\\epsilon_i^2\\)\nSum of the Squared Residuals (SSR/SSE). Big or small?\n\n\n\n\n\\[\nSSR = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2 \\\\\n= [y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i]^2\n\\]"
  },
  {
    "objectID": "slides/lec-10.html#derivation",
    "href": "slides/lec-10.html#derivation",
    "title": "CISC482 - Lecture10",
    "section": "Derivation",
    "text": "Derivation\n\nWill not be going through the derivation\nBasic idea is take the partial derivaitve of the funciton with respect to the parameters and set equal to 0.\nDo a bunch of algebra and you arrive at some nice equations\nFull derivation is here and here"
  },
  {
    "objectID": "slides/lec-10.html#classic-stats-result",
    "href": "slides/lec-10.html#classic-stats-result",
    "title": "CISC482 - Lecture10",
    "section": "Classic Stats Result",
    "text": "Classic Stats Result\n\n\\(\\beta_1 (slope) = \\frac{\\sum\\limits_{i=1}^{n}[(x_i-\\bar{x})(y_i- \\bar{y})]}{\\sum\\limits_{i=1}^{n} (x_i - \\bar{x})^2}\\)\n\\(\\beta_0\\) (intercept) - \\(\\bar{y} - \\beta_1 \\bar{x}\\)\n\n\ndf_r = df[['bill_length_mm', 'body_mass_g']].dropna()\nx = df_r.bill_length_mm\ny = df_r.body_mass_g\nx_bar = x.mean()\ny_bar = y.mean()\nprint(f\"Xbar: {x_bar:.1f}\")\nprint(f\"Ybar: {y_bar:.1f}\")\n\nXbar: 43.9\nYbar: 4201.8"
  },
  {
    "objectID": "slides/lec-10.html#computation",
    "href": "slides/lec-10.html#computation",
    "title": "CISC482 - Lecture10",
    "section": "Computation",
    "text": "Computation\n\nnumerator = np.sum((x - x_bar) * (y - y_bar))\ndenominator = np.sum((x - x_bar)**2)\nslope = numerator / denominator\nintercept = y_bar - slope * x_bar\nprint(f\"Slope: {slope:.1f}; \\nIntercept: {intercept:.1f}\");\n\nSlope: 87.4; \nIntercept: 362.3"
  },
  {
    "objectID": "slides/lec-10.html#another-classic-stats-result",
    "href": "slides/lec-10.html#another-classic-stats-result",
    "title": "CISC482 - Lecture10",
    "section": "Another Classic Stats Result",
    "text": "Another Classic Stats Result\n\\[\n\\begin{aligned}\\hat{\\beta}_1 &= \\frac{\\text{Cov}(x,y)}{s_x^2}\\end{aligned}\n\\]\nThe correlation between \\(x\\) and \\(y\\) is \\(r = \\frac{\\text{Cov}(x,y)}{s_x s_y}\\). Thus, \\(\\text{Cov}(x,y) = r s_xs_y\\). Plugging this into above, we have\n\\[\n\\hat{\\beta}_1 = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_ys_x}{s_x^2} = r\\frac{s_y}{s_x}\n\\]\n\\(\\beta_0\\) (intercept) - \\(\\bar{y} - \\beta_1 \\bar{x}\\)"
  },
  {
    "objectID": "slides/lec-10.html#computation-1",
    "href": "slides/lec-10.html#computation-1",
    "title": "CISC482 - Lecture10",
    "section": "Computation",
    "text": "Computation\n\nr = df_r.bill_length_mm.corr(df_r.body_mass_g)\nslope = r * (df_r.body_mass_g.std() / df_r.bill_length_mm.std())\nintercept = y_bar - slope * x_bar\nprint(f\"Slope: {slope:.1f}; \\nIntercept: {intercept:.1f}\")\n\nSlope: 87.4; \nIntercept: 362.3"
  },
  {
    "objectID": "slides/lec-10.html#another-full-example",
    "href": "slides/lec-10.html#another-full-example",
    "title": "CISC482 - Lecture10",
    "section": "Another Full Example",
    "text": "Another Full Example"
  },
  {
    "objectID": "slides/lec-10.html#matrix-math-result",
    "href": "slides/lec-10.html#matrix-math-result",
    "title": "CISC482 - Lecture10",
    "section": "Matrix Math Result",
    "text": "Matrix Math Result\n\\[\n\\begin{align*}\nA = \\begin{bmatrix}\nx_1 & 1\\\\\nx_2 & 1 \\\\\n... & ... \\\\\nx_n & 1\n\\end{bmatrix}\n\\qquad\ny = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n... \\\\\ny_n\n\\end{bmatrix}\n\\end{align*}\n\\qquad\n\\beta = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix}\n\\]\n\\[\n\\hat{y_1} = x_1 \\cdot \\beta_0 + 1 \\cdot \\beta_1 \\\\\n... \\\\\n\\hat{y} = A \\beta\n\\]\n\n\\[\n\\beta = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} = (A^TA)^{-1} A^Ty\n\\]"
  },
  {
    "objectID": "slides/lec-10.html#computation-of-matrix-result",
    "href": "slides/lec-10.html#computation-of-matrix-result",
    "title": "CISC482 - Lecture10",
    "section": "Computation of Matrix Result",
    "text": "Computation of Matrix Result\n\nn = len(df_r)\nprint(x.shape, type(x))\nx = x.values\nprint(x.shape,type(x))\nx = np.expand_dims(x, axis=1) # convert to matrix\nprint(x.shape)\nA = np.append(x, np.ones(shape=(n, 1)), axis=1) # add one column\nprint(A.shape)\ny = y.values\nprint(x[:5, :]) # sample of matrix\n# intercept = y_bar - slope * x_bar\n# print(f\"Slope: {slope:.1f}; \\nIntercept: {intercept:.1f}\")\n\n(342,) <class 'pandas.core.series.Series'>\n(342,) <class 'numpy.ndarray'>\n(342, 1)\n(342, 2)\n[[39.1]\n [39.5]\n [40.3]\n [36.7]\n [39.3]]"
  },
  {
    "objectID": "slides/lec-10.html#computation-of-matrix-result-1",
    "href": "slides/lec-10.html#computation-of-matrix-result-1",
    "title": "CISC482 - Lecture10",
    "section": "Computation of Matrix Result",
    "text": "Computation of Matrix Result\n\nbeta = np.linalg.inv(A.T @ A) @ A.T @ y\nprint(f\"Slope: {beta[0]:.1f}; \\nIntercept: {beta[1]:.1f}\")\n\nSlope: 87.4; \nIntercept: 362.3"
  },
  {
    "objectID": "slides/lec-10.html#class-activity-1",
    "href": "slides/lec-10.html#class-activity-1",
    "title": "CISC482 - Lecture10",
    "section": "Class Activity",
    "text": "Class Activity\nPractice Regression\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-03.html#schedule",
    "href": "slides/lec-03.html#schedule",
    "title": "CISC482 - Lecture03",
    "section": "Schedule",
    "text": "Schedule\n\nReading 2-1: Jan 25 @ 12PM, Wed\nReading 2-2: Jan 27 @ 12PM, Friday\nReading 2-3: Feb 1 @ 12PM, Wed\nHW2: Feb 1 @ Midnight, Wed"
  },
  {
    "objectID": "slides/lec-03.html#stats-for-data-science",
    "href": "slides/lec-03.html#stats-for-data-science",
    "title": "CISC482 - Lecture03",
    "section": "Stats for data science",
    "text": "Stats for data science\n\nData science relies on statistics to make data driven decisions\nSampling methods are used to efeciently collect data and reduce bias\n\n\n\n\n\n\n\nNote\n\n\nBias - anything that leads to a systematic difference between the true parameters of a population and the statistics used to estimate those parameters. E.g., sampling only men."
  },
  {
    "objectID": "slides/lec-03.html#its-hard",
    "href": "slides/lec-03.html#its-hard",
    "title": "CISC482 - Lecture03",
    "section": "It’s hard…",
    "text": "It’s hard…"
  },
  {
    "objectID": "slides/lec-03.html#sampling-errors",
    "href": "slides/lec-03.html#sampling-errors",
    "title": "CISC482 - Lecture03",
    "section": "Sampling Errors",
    "text": "Sampling Errors\n\nA small, systematic polling error made a big difference\nAll polls were off in the same direction (5 pts) in swing states\nCorrelatated sampling errors in the midwest\nFailure to appreciate uncertainty"
  },
  {
    "objectID": "slides/lec-03.html#stats-for-data-science-1",
    "href": "slides/lec-03.html#stats-for-data-science-1",
    "title": "CISC482 - Lecture03",
    "section": "Stats for data science",
    "text": "Stats for data science\n\n\n\nDescriptive statistics -> explore visualizations\nInferential statistics -> modeling and estimation\nStatisitcs is foundational to ensure results are interpreted correctly\n\n\n\n\n\n\nSpeaker notes go here."
  },
  {
    "objectID": "slides/lec-03.html#sampling",
    "href": "slides/lec-03.html#sampling",
    "title": "CISC482 - Lecture03",
    "section": "Sampling",
    "text": "Sampling\n\nPopulation - Entire set of individuals, items, or events of interest\nObservational Unit - individual item or event\nSample - subset of observational units from the population"
  },
  {
    "objectID": "slides/lec-03.html#types-of-sampling",
    "href": "slides/lec-03.html#types-of-sampling",
    "title": "CISC482 - Lecture03",
    "section": "Types of Sampling",
    "text": "Types of Sampling\n\n\nRandom Sampling\n\nOU are selected at random\n\nStratified Sampling\n\nPopulation is divided into groups (primary feature). Each group is sampled.\n\nCluster Sampling\n\nPopulation divided into groups (not a primary feature, geography)\n\nSystematic Sampling\n\nEvery k’th observational unit is sampled\n\nConvenience Sampling\n\nOU are selected that are easier"
  },
  {
    "objectID": "slides/lec-03.html#observational-vs-experiement",
    "href": "slides/lec-03.html#observational-vs-experiement",
    "title": "CISC482 - Lecture03",
    "section": "Observational vs Experiement",
    "text": "Observational vs Experiement\n\nObservational\n\nObserving or collecting data\nNot trying to control or influence an outcome\n\nExperimental\n\nYou are controlling a varaible\nYou manipulate that variable to get a different response"
  },
  {
    "objectID": "slides/lec-03.html#descriptive-statistics",
    "href": "slides/lec-03.html#descriptive-statistics",
    "title": "CISC482 - Lecture03",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics"
  },
  {
    "objectID": "slides/lec-03.html#oveview",
    "href": "slides/lec-03.html#oveview",
    "title": "CISC482 - Lecture03",
    "section": "Oveview",
    "text": "Oveview\n\nTerminology\nMeasure of center\nMeasure of spread\nMeasure of position\nMeasure of shape"
  },
  {
    "objectID": "slides/lec-03.html#terminology",
    "href": "slides/lec-03.html#terminology",
    "title": "CISC482 - Lecture03",
    "section": "Terminology",
    "text": "Terminology\n\nDescriptive Statistics - summarize and describe a features important characteristics\ndistribution - the possible values the feature can take\ncluster - a distinct group of neighboring values in a distribution\ntails - the end values of a distributution"
  },
  {
    "objectID": "slides/lec-03.html#terminology---visualized",
    "href": "slides/lec-03.html#terminology---visualized",
    "title": "CISC482 - Lecture03",
    "section": "Terminology - Visualized",
    "text": "Terminology - Visualized"
  },
  {
    "objectID": "slides/lec-03.html#measure-of-center",
    "href": "slides/lec-03.html#measure-of-center",
    "title": "CISC482 - Lecture03",
    "section": "Measure of Center",
    "text": "Measure of Center\n\nMean - average, sum of all values divided by the total number of values, n \\[\n\\frac{1}{n} \\sum_{i=i}^{n} x_{i}\n\\]\nMedian - the middle value of the ordered data"
  },
  {
    "objectID": "slides/lec-03.html#code-example",
    "href": "slides/lec-03.html#code-example",
    "title": "CISC482 - Lecture03",
    "section": "Code Example!",
    "text": "Code Example!\n\nheights = [5.5, 5.7, 5.8, 5.9]\navg_height = sum(heights) / len(heights)\nprint(f\"Average Height: {avg_height:.2f}\")\n\nAverage Height: 5.72\n\n\n\n\nUsing Numpy\n\nimport numpy as np\nheights = np.array([5.5, 5.7, 5.8, 5.9, 6.2])\navg_height = np.average(heights)\nprint(f\"Average Height: {avg_height:.2f}\")\n\nAverage Height: 5.82"
  },
  {
    "objectID": "slides/lec-03.html#what-is-numpy",
    "href": "slides/lec-03.html#what-is-numpy",
    "title": "CISC482 - Lecture03",
    "section": "What is NumPy",
    "text": "What is NumPy\n\nNumPy is the fundamental package for scientific computing in Python.\nPython library that provides a multidimensional array object.\nStores data very effeciently very fast\n\n\na = np.array([1, 2])\n\n\n2D array - rows and columns\nb = np.array([\n  [1, 2], # first row\n  [3, 4]  # second row\n])"
  },
  {
    "objectID": "slides/lec-03.html#question",
    "href": "slides/lec-03.html#question",
    "title": "CISC482 - Lecture03",
    "section": "Question",
    "text": "Question\nnp.average(...) - finds the average\n\n\n\n\n\n\nTip\n\n\nWhat function to get the median?\n\n\n\n\n\nheights = np.array([5.5, 5.7, 5.8, 5.9, 6.2])\nmedian_height = np.median(heights)\nprint(f\"Median Height: {median_height:.2f}\")\n\nMedian Height: 5.80"
  },
  {
    "objectID": "slides/lec-03.html#spread",
    "href": "slides/lec-03.html#spread",
    "title": "CISC482 - Lecture03",
    "section": "Spread",
    "text": "Spread"
  },
  {
    "objectID": "slides/lec-03.html#spread-terminology",
    "href": "slides/lec-03.html#spread-terminology",
    "title": "CISC482 - Lecture03",
    "section": "Spread Terminology",
    "text": "Spread Terminology\n\nrange - distance between the min and max\ninterquartile range (IQR) - range of the middle 50%\nvariance - the average squared distance between a feature and its discribution mean\n\n\\[\n\\sigma^2 = Var(x) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x} )^2}{n-1}\n\\]\n\nStandard deviation - \\(\\sigma = sqrt(Var(X))\\)"
  },
  {
    "objectID": "slides/lec-03.html#postion-terminology-quantiles",
    "href": "slides/lec-03.html#postion-terminology-quantiles",
    "title": "CISC482 - Lecture03",
    "section": "Postion Terminology (Quantiles)",
    "text": "Postion Terminology (Quantiles)"
  },
  {
    "objectID": "slides/lec-03.html#example",
    "href": "slides/lec-03.html#example",
    "title": "CISC482 - Lecture03",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/lec-03.html#measures-of-shape",
    "href": "slides/lec-03.html#measures-of-shape",
    "title": "CISC482 - Lecture03",
    "section": "Measures of Shape",
    "text": "Measures of Shape\n\n\nSkewness - measure of the amount and direction of skew\nKurtosis - measure of tail heaviness"
  },
  {
    "objectID": "slides/lec-03.html#mean",
    "href": "slides/lec-03.html#mean",
    "title": "CISC482 - Lecture03",
    "section": "Mean",
    "text": "Mean\n\n                            # mean,  std,    n\nsamples = np.random.normal(loc=5.0, scale=1, size=11)\nsamples\n\narray([6.624, 4.388, 4.472, 3.927, 5.865, 2.698, 6.745, 4.239, 5.319,\n       4.751, 6.462])\n\n\nHow would I get the mean?\n\n\nprint(np.mean(samples))\n\n5.044609002634907"
  },
  {
    "objectID": "slides/lec-03.html#standard-deviation",
    "href": "slides/lec-03.html#standard-deviation",
    "title": "CISC482 - Lecture03",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\n\nstd = np.std(samples)\nprint(f\"The standard deviation is: {std:.2f}\")\n\nThe standard deviation is: 1.22\n\n\n\n\nThe variance?\n\n\n\nvar = std * std\nprint(f\"The variance is: {var:.2f}\")\n\nThe variance is: 1.49"
  },
  {
    "objectID": "slides/lec-03.html#quantiles",
    "href": "slides/lec-03.html#quantiles",
    "title": "CISC482 - Lecture03",
    "section": "Quantiles",
    "text": "Quantiles\n\n\nsamples_sorted = np.sort(samples)\nprint(samples_sorted)\n\n[2.698 3.927 4.239 4.388 4.472 4.751 5.319 5.865 6.462 6.624 6.745]\n\n\n\n\nGetting the quantile\n\n\n\nfifty_percent_quantile = np.quantile(samples, 0.50)\nmedian = np.median(samples)\n\nprint(f\"{fifty_percent_quantile:.3f}\")\nprint(f\"{median:.3f}\")\n\n4.751\n4.751\n\n\n\n\n\nquantiles = np.quantile(samples, [0.25, 0.5, 0.75])\n\nprint(quantiles)\n\n[4.314 4.751 6.164]"
  },
  {
    "objectID": "slides/lec-03.html#shape",
    "href": "slides/lec-03.html#shape",
    "title": "CISC482 - Lecture03",
    "section": "Shape",
    "text": "Shape\nAdvanced statistics -> I recommend using the library scipy. This library is built on top of numpy but has more functionality.\n\n\nfrom scipy.stats import skewnorm\nsamples_skewed = skewnorm.rvs(3, loc=15, scale=2, size=1000)\nsamples = skewnorm.rvs(0, loc=5, scale=1, size=1000)\n\n\n\n<seaborn.axisgrid.FacetGrid at 0x7f8ee577eec0>"
  },
  {
    "objectID": "slides/lec-03.html#skewness-and-kurtosis",
    "href": "slides/lec-03.html#skewness-and-kurtosis",
    "title": "CISC482 - Lecture03",
    "section": "Skewness and Kurtosis",
    "text": "Skewness and Kurtosis\nCalculate the skewness\n\n\nimport scipy.stats as stats\nprint(f\"Skewed sample data set, skewnewss is: {stats.skew(samples_skewed):.3f}\")\nprint(f\"Normal sample data set, skewnewss is: {stats.skew(samples):.3f}\")\n\nSkewed sample data set, skewnewss is: 0.790\nNormal sample data set, skewnewss is: -0.003\n\n\n\n\nCalculate the kurtosis\n\nimport scipy.stats as stats\nprint(f\"Skewed sample data set, kurtosis is: {stats.kurtosis(samples_skewed):.3f}\")\nprint(f\"Normal sample data set, kurtosis is: {stats.kurtosis(samples):.3f}\")\n\nSkewed sample data set, kurtosis is: 0.938\nNormal sample data set, kurtosis is: -0.067\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nThis skewed distribution is not very good at demonstrating kurtosis."
  },
  {
    "objectID": "slides/lec-03.html#all",
    "href": "slides/lec-03.html#all",
    "title": "CISC482 - Lecture03",
    "section": "All",
    "text": "All\n\nimport scipy.stats as stats\nstats.describe(samples)\n\nDescribeResult(nobs=1000, minmax=(1.7616568032476234, 7.787361447950662), mean=5.053665979218166, variance=1.0126662448100565, skewness=-0.0026145821525120016, kurtosis=-0.06654059199852824)\n\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-08.html#schedule",
    "href": "slides/lec-08.html#schedule",
    "title": "CISC482 - Lecture08",
    "section": "Schedule",
    "text": "Schedule\n\nReading 4-1: Feb 10 @ 12PM, Friday\nReading 4-2: Feb 15 @ 12PM, Wednesday\nHW3: Feb 15 @ Midnight, Wednesday\nExam 1 - Feb 15 in class\nTopic Ideas - Feb 22 @ Midnight"
  },
  {
    "objectID": "slides/lec-08.html#cs-faculty-candidate",
    "href": "slides/lec-08.html#cs-faculty-candidate",
    "title": "CISC482 - Lecture08",
    "section": "CS Faculty Candidate",
    "text": "CS Faculty Candidate\n\nRazuan Hossain is here!\nPlease attend a meet and greet at 3:15 in SBSC 112\nExtra Credit!"
  },
  {
    "objectID": "slides/lec-08.html#today",
    "href": "slides/lec-08.html#today",
    "title": "CISC482 - Lecture08",
    "section": "Today",
    "text": "Today\n\nClass Activity, building graphs\nExam Review Sheet"
  },
  {
    "objectID": "slides/lec-08.html#class-activity-1",
    "href": "slides/lec-08.html#class-activity-1",
    "title": "CISC482 - Lecture08",
    "section": "Class Activity",
    "text": "Class Activity\n📋 Class Activity 04 - Practice Seaborn"
  },
  {
    "objectID": "slides/lec-08.html#you-can-do-it",
    "href": "slides/lec-08.html#you-can-do-it",
    "title": "CISC482 - Lecture08",
    "section": "You can do it!",
    "text": "You can do it!\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-15.html#schedule",
    "href": "slides/lec-15.html#schedule",
    "title": "CISC482 - Lecture15",
    "section": "Schedule",
    "text": "Schedule\n\nReading 6-1: Mar 08 @ 12PM, Wednesday\nReading 6-2: Mar 10 @ 12PM, Friday\nProposal: Mar 22, Wednesday\nHW5 - Mar 29 @ Midnight, Wednesday"
  },
  {
    "objectID": "slides/lec-15.html#today",
    "href": "slides/lec-15.html#today",
    "title": "CISC482 - Lecture15",
    "section": "Today",
    "text": "Today\n\nReview Overfit/Underfit\nReivew Regression and Classification Metrics\nTraining vs Testing Set"
  },
  {
    "objectID": "slides/lec-15.html#overfitunderfit",
    "href": "slides/lec-15.html#overfitunderfit",
    "title": "CISC482 - Lecture15",
    "section": "Overfit/Underfit",
    "text": "Overfit/Underfit\n\nOverfit - model is too complex to fit the data well.\n\nFitting the data too closely\nIncorporating too much noise (meaningless variation)\nMisses the general trend\n\nUnderfit - model is too simple to fit the data well.\n\nLarge systematic errror"
  },
  {
    "objectID": "slides/lec-15.html#question---underfit-or-overfit",
    "href": "slides/lec-15.html#question---underfit-or-overfit",
    "title": "CISC482 - Lecture15",
    "section": "Question - Underfit or Overfit?",
    "text": "Question - Underfit or Overfit?"
  },
  {
    "objectID": "slides/lec-15.html#regression-metrics",
    "href": "slides/lec-15.html#regression-metrics",
    "title": "CISC482 - Lecture15",
    "section": "Regression Metrics",
    "text": "Regression Metrics\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = \\frac{\\text{variation explained by regression}}{\\text{total variation in the data}} = \\frac{\\sum (\\hat{y}_i - \\bar{y})^2}{\\sum (y_i - \\bar{y})^2}\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\nWhat is the range? Units?"
  },
  {
    "objectID": "slides/lec-15.html#binary-classification-metrics",
    "href": "slides/lec-15.html#binary-classification-metrics",
    "title": "CISC482 - Lecture15",
    "section": "Binary Classification Metrics",
    "text": "Binary Classification Metrics\n\nTrue Positive (TP) is an outcome that was correctly identified as positive\nTrue Negative (TN) is an outcome that was correctly identified as negative.\nFalse Positive (FP) is an outcome that was incorrectly identified as positive\nFalse Negative (TN) is an outcome that was incorrectly identified as negative"
  },
  {
    "objectID": "slides/lec-15.html#metrics",
    "href": "slides/lec-15.html#metrics",
    "title": "CISC482 - Lecture15",
    "section": "Metrics",
    "text": "Metrics\n\nAccuracy: \\(\\frac{TP + TN}{TP + TN + FP + FN}\\)\nPrecision: \\(\\frac{TP}{TP + FP}\\)\nRecall: \\(\\frac{TP}{TP + FN}\\)"
  },
  {
    "objectID": "slides/lec-15.html#purpose-of-model-evaluation",
    "href": "slides/lec-15.html#purpose-of-model-evaluation",
    "title": "CISC482 - Lecture15",
    "section": "Purpose of model evaluation",
    "text": "Purpose of model evaluation\n\n\\(R^2\\), \\(recall\\), etc. tells us how our model is doing to predict the data we already have\nBut generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e. out-of-sample prediction\nWe have a couple ways of simulating out-of-sample prediction before actually getting new data to evaluate the performance of our models"
  },
  {
    "objectID": "slides/lec-15.html#splitting-data",
    "href": "slides/lec-15.html#splitting-data",
    "title": "CISC482 - Lecture15",
    "section": "Splitting data",
    "text": "Splitting data\n\nThere are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available leaves us with no other data to assess our choices\nWe can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we’ve done so far)"
  },
  {
    "objectID": "slides/lec-15.html#the-split",
    "href": "slides/lec-15.html#the-split",
    "title": "CISC482 - Lecture15",
    "section": "The Split",
    "text": "The Split\n\nTraining data is used to fit a model.\nValidation data is used to evaluate model performance while adjusting hyperparameter estimates and conducting feature selection. This is not always needed!\nTest data is used to evaluate final model performance and compare different models.\nThe ratio for this split: 80/10/10 or 70/10/20"
  },
  {
    "objectID": "slides/lec-15.html#visualization",
    "href": "slides/lec-15.html#visualization",
    "title": "CISC482 - Lecture15",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "slides/lec-15.html#an-example",
    "href": "slides/lec-15.html#an-example",
    "title": "CISC482 - Lecture15",
    "section": "An Example!",
    "text": "An Example!\n\n\nCode\nfrom sklearn.metrics import r2_score\nlinear_model = LinearRegression()\nlinear_model.fit(X, y)\ndegree = 5\nprint(f\"Linear Model R^2 = {r2_score(y, linear_model.predict(X)):.2f}\")\n\nquadratic_model = np.poly1d(np.polyfit(x, y, degree)) # quadratic\nprint(f\"Polynomial Model R^2 = {r2_score(y, quadratic_model(x)):.2f}\")\n\nax = sns.scatterplot(x=x, y=y, label=\"All Data\")\nax.plot(x, linear_model.predict(X), color='r', label='Linear Regression')\nax.plot(x, quadratic_model(x), color='m', label='Polynomial Regression')\n# ax.scatter(x, quadratic_model(x), color='m')\nax.legend();\n\n\nLinear Model R^2 = 0.55\nPolynomial Model R^2 = 0.64"
  },
  {
    "objectID": "slides/lec-15.html#traintest-split",
    "href": "slides/lec-15.html#traintest-split",
    "title": "CISC482 - Lecture15",
    "section": "Train/Test Split",
    "text": "Train/Test Split\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=0)\n\nlinear_model.fit(X_train, y_train)\nquadratic_model = np.poly1d(np.polyfit(X_train[:,0], y_train, degree)) # quadratic\n\nprint(f\"TRAIN SET - Linear Model R^2 = {r2_score(y_train, linear_model.predict(X_train)):.2f}; Polynomial Model R^2 = {r2_score(y_train, quadratic_model(X_train[:,0])):.2f}\")\nprint(f\"TEST SET - Linear Model R^2 = {r2_score(y_test, linear_model.predict(X_test)):.2f}; Polynomial Model R^2 = {r2_score(y_test, quadratic_model(X_test[:,0])):.2f}\")\n\n\nfig, ax = plt.subplots(nrows=1, ncols=2) # create 2 plots!\n# Plot training result\nsns.scatterplot(x=X_train[:,0], y=y_train, ax=ax[0], label=\"Training Data\")\nax[0].plot(np.sort(X_train[:, 0]), linear_model.predict(np.sort(X_train, axis=0)), color='r', label='Linear Regression')\nax[0].plot(np.sort(X_train[:, 0]), quadratic_model(np.sort(X_train[:, 0])), color='m', label='Polynomial Regression');\n# ax[0].scatter(np.sort(X_train[:, 0]), quadratic_model(np.sort(X_train[:, 0])), color='m');\nax[0].set_title(\"Training Set\")\nax[0].legend()\n# Plot testing result\nsns.scatterplot(x=X_test[:,0], y=y_test, ax=ax[1], label=\"Testing Data\")\nax[1].plot(np.sort(X_test[:, 0]), linear_model.predict(np.sort(X_test, axis=0)), color='r', label='Linear Regression')\nax[1].plot(np.sort(X_test[:, 0]), quadratic_model(np.sort(X_test[:, 0])), color='m', label='Polynomial Regression');\n# ax[1].scatter(np.sort(X_test[:, 0]), quadratic_model(np.sort(X_test[:, 0])), color='m');\nax[1].set_title(\"Testing Set\")\nax[1].legend();\n\n\nTRAIN SET - Linear Model R^2 = 0.44; Polynomial Model R^2 = 0.62\nTEST SET - Linear Model R^2 = 0.65; Polynomial Model R^2 = 0.41\n\n\n\n\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-01.html#meet-the-professor",
    "href": "slides/lec-01.html#meet-the-professor",
    "title": "Welcome to CISC 482",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\nChemical Engineering & Computer Science @ BYU\nControl Systems Engineer & NASA Research Scientist\nRobotics PhD @ UMICH\n\nMachine Learning  Artificial Intelligence Computer Vision"
  },
  {
    "objectID": "slides/lec-01.html#welcome-to-computer-systems-seminar",
    "href": "slides/lec-01.html#welcome-to-computer-systems-seminar",
    "title": "Welcome to CISC 482",
    "section": "Welcome to Computer Systems Seminar",
    "text": "Welcome to Computer Systems Seminar\n\n\nThis course is designed to address various current technical and managerial problems encountered in computer information systems, including those dealing with hardware architecture, systems software, and applications software.\n\n\n\n\n\nTeach whatever you want!\n\n\n\n\n\nPicutre of James O’Brien"
  },
  {
    "objectID": "slides/lec-01.html#welcome-to-computer-systems-seminar-intro-to-data-science",
    "href": "slides/lec-01.html#welcome-to-computer-systems-seminar-intro-to-data-science",
    "title": "Welcome to CISC 482",
    "section": "Welcome to ~Computer Systems Seminar Intro to Data Science",
    "text": "Welcome to ~Computer Systems Seminar Intro to Data Science\n\nLogo for Class, Example of Group Separation"
  },
  {
    "objectID": "slides/lec-01.html#data-science",
    "href": "slides/lec-01.html#data-science",
    "title": "Welcome to CISC 482",
    "section": "Data Science",
    "text": "Data Science\n\n\nFirst Half\n\nProbability and Stats\nData Wrangling\nData Exploration and Viz\nRegression\nEvaluation Model Performance\n\n\nSecond Half\n\nSupervised Learning\nUnsupervised Learning\nCapstone Project Work"
  },
  {
    "objectID": "slides/lec-01.html#course-faq",
    "href": "slides/lec-01.html#course-faq",
    "title": "Welcome to CISC 482",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Probability and Statistics and Basic Programming (Python)\nWill we be doing computing? Yes. We will use Python Jupyter Notebooks\nWill we learn the mathematical theory? Yes and No. The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression."
  },
  {
    "objectID": "slides/lec-01.html#course-learning-objectives",
    "href": "slides/lec-01.html#course-learning-objectives",
    "title": "Welcome to CISC 482",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nUnderstand and be able to use supervised and unsupervised learning methods\nAssess whether a proposed model is appropriate and describe its performance and limitations.\nUse Google Collab to write reproducible reports.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-01.html#examples-of-data-science-in-practice",
    "href": "slides/lec-01.html#examples-of-data-science-in-practice",
    "title": "Welcome to CISC 482",
    "section": "Examples of data science in practice",
    "text": "Examples of data science in practice\n\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight’s 2020 Presidential Forecast Works — And What’s Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it’s so freaking hard to make a good COVID-19 model\nHow severe is the threat of wildfire to your home?"
  },
  {
    "objectID": "slides/lec-01.html#getting-to-know-you",
    "href": "slides/lec-01.html#getting-to-know-you",
    "title": "Welcome to CISC 482",
    "section": "Getting to know you",
    "text": "Getting to know you\n\nYour name, major\nIf you could write a book, what would it be about?\nWhat is your dream job?"
  },
  {
    "objectID": "slides/lec-01.html#zybooks",
    "href": "slides/lec-01.html#zybooks",
    "title": "Welcome to CISC 482",
    "section": "Zybooks",
    "text": "Zybooks\nOur required book is online: Zybooks\n\nSign in or create an account at learn.zybooks.com\nEnter zyBook code: SPRINGFIELDCISC482CastagnoSpring2023\nSubscribe (~$58)"
  },
  {
    "objectID": "slides/lec-01.html#zybook-walkthrough",
    "href": "slides/lec-01.html#zybook-walkthrough",
    "title": "Welcome to CISC 482",
    "section": "Zybook Walkthrough",
    "text": "Zybook Walkthrough"
  },
  {
    "objectID": "slides/lec-01.html#course-toolkit",
    "href": "slides/lec-01.html#course-toolkit",
    "title": "Welcome to CISC 482",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nZybook: https://learn.zybooks.com/)\nGoogle Collab (Free): https://colab.research.google.com/\nDiscussion forum: Use Brightspace Discussion. Activities -> Discussions\nAssignment submission and feedback: Submit through Brightspace\n\n\n\n\n\n\n\nImportant\n\n\nPlease purchase the book as soon as possible. Reading assignments are due this Sunday night!"
  },
  {
    "objectID": "slides/lec-01.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-01.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to CISC 482",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings\nParticipate: Attend and actively participate in lectures and activities, office hours\nPractice: Practice applying statistical concepts and computing with application exercises during lecture (usually 30 minutes every Friday)\nPerform: Put together what you’ve learned to analyze real-world data\n\nHomework assignments x 6 (individual submission, but encouraged to collaborate)\nTwo exams\nTerm project (Core Capstone Work) presented during the final exam period"
  },
  {
    "objectID": "slides/lec-01.html#cadence",
    "href": "slides/lec-01.html#cadence",
    "title": "Welcome to CISC 482",
    "section": "Cadence",
    "text": "Cadence\n\n\nLectures: Posted before lecture. Encouraged to read before and follow along\nHWs: Posted Wednesday morning, due following Wednesday @ midnight\nProject: Deadlines throughout the semester, with some lab and lecture time dedicated to working on them, and most work done outside of class. This is a major part of this class."
  },
  {
    "objectID": "slides/lec-01.html#grading",
    "href": "slides/lec-01.html#grading",
    "title": "Welcome to CISC 482",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nClass Reading\n15%\n\n\nHomework\n30% (6% x 5)\n\n\nProject\n25%\n\n\nExam 01\n15%\n\n\nExam 02\n15%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/lec-01.html#support",
    "href": "slides/lec-01.html#support",
    "title": "Welcome to CISC 482",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum on Brightspace\nAung Thet Htwe is our graduate assistant for this course.\n\nReserve and Appointment: https://calendly.com/aung-t-htwe/r-and-data-science-tutoring-with-aung"
  },
  {
    "objectID": "slides/lec-01.html#announcements",
    "href": "slides/lec-01.html#announcements",
    "title": "Welcome to CISC 482",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Brightspace and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day"
  },
  {
    "objectID": "slides/lec-01.html#diversity-inclusion",
    "href": "slides/lec-01.html#diversity-inclusion",
    "title": "Welcome to CISC 482",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official Springfield College records, please let me know!\nPlease let me know your preferred pronouns. You’ll also be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-01.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-01.html#late-work-waivers-regrades-policy",
    "title": "Welcome to CISC 482",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nNo Late Work is accepted unless do to illness or pre approved absence\nThree (3) of your lowest reading assignments will be dropped\nNo HW (labs) are dropped\nNo late submission for project work"
  },
  {
    "objectID": "slides/lec-01.html#collaboration-policy",
    "href": "slides/lec-01.html#collaboration-policy",
    "title": "Welcome to CISC 482",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-01.html#sharing-reusing-code-policy",
    "href": "slides/lec-01.html#sharing-reusing-code-policy",
    "title": "Welcome to CISC 482",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g. StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/lec-01.html#most-importantly",
    "href": "slides/lec-01.html#most-importantly",
    "title": "Welcome to CISC 482",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-01.html#five-tips-for-success",
    "href": "slides/lec-01.html#five-tips-for-success",
    "title": "Welcome to CISC 482",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class (reading, participation activity, challenge quizzes)\nAsk questions.\nDo the homeworks\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStart thinking about your project early"
  },
  {
    "objectID": "slides/lec-01.html#this-weeks-tasks",
    "href": "slides/lec-01.html#this-weeks-tasks",
    "title": "Welcome to CISC 482",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nSign up for the Zybook\nRead the syllabus\nHW1 - Markdown\n\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-13.html#schedule",
    "href": "slides/lec-13.html#schedule",
    "title": "CISC482 - Lecture13",
    "section": "Schedule",
    "text": "Schedule\n\nReading 6-1: Mar 08 @ 12PM, Wednesday\nHW4 - Mar 08 @ Midnight\nProposal: Mar 22, Wednesday"
  },
  {
    "objectID": "slides/lec-13.html#today",
    "href": "slides/lec-13.html#today",
    "title": "CISC482 - Lecture13",
    "section": "Today",
    "text": "Today\n\nReview Linear Regression\nReview Logistic Regression\nPractice Problems"
  },
  {
    "objectID": "slides/lec-13.html#give-me-the-function-models",
    "href": "slides/lec-13.html#give-me-the-function-models",
    "title": "CISC482 - Lecture13",
    "section": "Give me the function models",
    "text": "Give me the function models\n\n\nSimple Linear Regression\n\n\\(\\hat{y} = \\beta_0 + x + \\beta_1\\)\n\nSimple Polynomial Linear Regression\n\n\\(\\hat{y} = \\beta_0 + \\beta_1 x + ... + \\beta_k x^k\\)\n\nMultiple Linear Regression\n\n\\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + ... \\beta_k x_k\\)\n\nMultiple (Variable) Polynomial Regression\n\n\\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\beta_3 x_1 x_2 + \\beta_4 x_2 + \\beta_5 x_2^2\\)"
  },
  {
    "objectID": "slides/lec-13.html#logistic-regression",
    "href": "slides/lec-13.html#logistic-regression",
    "title": "CISC482 - Lecture13",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\n\nWe often use logistic regression for classification problems? Then why do we call it logistic regression? What is being regressed?\nWhat is the function for logistic regression?\n\n\\(\\hat{p}(x) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1+ e^{\\beta_0 + \\beta_1 x}}\\)\n\nWhat do we call this non-linear function? HINT - what shape does it make?"
  },
  {
    "objectID": "slides/lec-13.html#why-not-linear-regression",
    "href": "slides/lec-13.html#why-not-linear-regression",
    "title": "CISC482 - Lecture13",
    "section": "Why not Linear Regression?",
    "text": "Why not Linear Regression?\n\nLinear Regression is strongly affected by outliers\nLinear Regression is strongly affected by imbalanced classes"
  },
  {
    "objectID": "slides/lec-13.html#visual",
    "href": "slides/lec-13.html#visual",
    "title": "CISC482 - Lecture13",
    "section": "Visual",
    "text": "Visual"
  },
  {
    "objectID": "slides/lec-06.html#schedule",
    "href": "slides/lec-06.html#schedule",
    "title": "CISC482 - Lecture06",
    "section": "Schedule",
    "text": "Schedule\n\nReading 3-1: Feb 3 @ 12PM, Today!\nReading 3-2: Feb 8 @ 12PM, Wednesday\nReading 4-1: Feb 10 @ 12PM, Friday\nHW3: Feb 15 @ Midnight, Wednesday\nExam 1: Feb 15 in Class"
  },
  {
    "objectID": "slides/lec-06.html#cs-faculty-candidate",
    "href": "slides/lec-06.html#cs-faculty-candidate",
    "title": "CISC482 - Lecture06",
    "section": "CS Faculty Candidate",
    "text": "CS Faculty Candidate\n\nBenz Tran is here today!\nPlease attend a meet and greet at 3:15 in SBSC 112\nExtra Credit!"
  },
  {
    "objectID": "slides/lec-06.html#steps",
    "href": "slides/lec-06.html#steps",
    "title": "CISC482 - Lecture06",
    "section": "Steps",
    "text": "Steps\n\nDiscovery - Familiarize with source data\nStructuring - Transforms features to uniform formats, units, and scales.\nCleaning - Removes or replaces missing and outlier data.\nEnriching - Derives new features from existing features and appends new data from external sources.\nValidating - Verifies that the dataset is internally consistent and accurate\nPublishing - Makes the dataset available to others"
  },
  {
    "objectID": "slides/lec-06.html#example",
    "href": "slides/lec-06.html#example",
    "title": "CISC482 - Lecture06",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/lec-06.html#extract-transform-load",
    "href": "slides/lec-06.html#extract-transform-load",
    "title": "CISC482 - Lecture06",
    "section": "Extract, Transform, Load",
    "text": "Extract, Transform, Load\n\nExtract, Transform, Load (ETL) is a process that extracts data from databases, transforms the data, and loads the data into an analytic database.\nSimilar to data wrangling: process data, clean, enrich, etc.\nDifference is that data wrangling is more informal, where ETL is a usually a business process or service."
  },
  {
    "objectID": "slides/lec-06.html#what-is-pandas",
    "href": "slides/lec-06.html#what-is-pandas",
    "title": "CISC482 - Lecture06",
    "section": "What is Pandas",
    "text": "What is Pandas\n\n\n\nPandas is an open source Python package\nWidely used for data science/data analysis\nKey idea is organizing data into a dataframe\nTabular data, effecient queries, uses numpy if possible"
  },
  {
    "objectID": "slides/lec-06.html#loading-pandas-from-python-lists",
    "href": "slides/lec-06.html#loading-pandas-from-python-lists",
    "title": "CISC482 - Lecture06",
    "section": "Loading Pandas from python lists",
    "text": "Loading Pandas from python lists\n\n\nimport pandas as pd\nd = {'a': [1, 2, 3], \n    'b': [4.0, 5.0, 6.0]\n    }\ndf = pd.DataFrame(data=d)\ndf\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      4.0\n    \n    \n      1\n      2\n      5.0\n    \n    \n      2\n      3\n      6.0\n    \n  \n\n\n\n\n\n\nPandas creates an index automatically (unnamed column)"
  },
  {
    "objectID": "slides/lec-06.html#loading-pandas-from-numpy",
    "href": "slides/lec-06.html#loading-pandas-from-numpy",
    "title": "CISC482 - Lecture06",
    "section": "Loading Pandas from NumPy",
    "text": "Loading Pandas from NumPy\n\n\nd = {'a': np.array([1, 2, 3]), \n    'b': np.array([4.0, 5.0, 6.0])\n    }\ndf = pd.DataFrame(data=d)\ndf\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      4.0\n    \n    \n      1\n      2\n      5.0\n    \n    \n      2\n      3\n      6.0\n    \n  \n\n\n\n\n\n\nYou can also use NumPy arrays"
  },
  {
    "objectID": "slides/lec-06.html#csv-files",
    "href": "slides/lec-06.html#csv-files",
    "title": "CISC482 - Lecture06",
    "section": "CSV Files",
    "text": "CSV Files\nLink"
  },
  {
    "objectID": "slides/lec-06.html#loading-pandas-from-a-csv",
    "href": "slides/lec-06.html#loading-pandas-from-a-csv",
    "title": "CISC482 - Lecture06",
    "section": "Loading Pandas from a CSV",
    "text": "Loading Pandas from a CSV\n\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      studyName\n      Sample Number\n      Species\n      Region\n      Island\n      Stage\n      Individual ID\n      Clutch Completion\n      Date Egg\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Delta 15 N (o/oo)\n      Delta 13 C (o/oo)\n      Comments\n    \n  \n  \n    \n      0\n      PAL0708\n      1\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N1A1\n      Yes\n      2007-11-11\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n      NaN\n      NaN\n      Not enough blood for isotopes.\n    \n    \n      1\n      PAL0708\n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N1A2\n      Yes\n      2007-11-11\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      8.94956\n      -24.69454\n      NaN\n    \n    \n      2\n      PAL0708\n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A1\n      Yes\n      2007-11-16\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      8.36821\n      -25.33302\n      NaN\n    \n    \n      3\n      PAL0708\n      4\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N2A2\n      Yes\n      2007-11-16\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      Adult not sampled.\n    \n    \n      4\n      PAL0708\n      5\n      Adelie Penguin (Pygoscelis adeliae)\n      Anvers\n      Torgersen\n      Adult, 1 Egg Stage\n      N3A1\n      Yes\n      2007-11-16\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      8.76651\n      -25.32426\n      NaN"
  },
  {
    "objectID": "slides/lec-06.html#pandas-methods---info",
    "href": "slides/lec-06.html#pandas-methods---info",
    "title": "CISC482 - Lecture06",
    "section": "Pandas Methods - Info",
    "text": "Pandas Methods - Info\n\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 344 entries, 0 to 343\nData columns (total 17 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   studyName            344 non-null    object \n 1   Sample Number        344 non-null    int64  \n 2   Species              344 non-null    object \n 3   Region               344 non-null    object \n 4   Island               344 non-null    object \n 5   Stage                344 non-null    object \n 6   Individual ID        344 non-null    object \n 7   Clutch Completion    344 non-null    object \n 8   Date Egg             344 non-null    object \n 9   Culmen Length (mm)   342 non-null    float64\n 10  Culmen Depth (mm)    342 non-null    float64\n 11  Flipper Length (mm)  342 non-null    float64\n 12  Body Mass (g)        342 non-null    float64\n 13  Sex                  333 non-null    object \n 14  Delta 15 N (o/oo)    330 non-null    float64\n 15  Delta 13 C (o/oo)    331 non-null    float64\n 16  Comments             54 non-null     object \ndtypes: float64(6), int64(1), object(10)\nmemory usage: 45.8+ KB"
  },
  {
    "objectID": "slides/lec-06.html#select-only-interesting-columns",
    "href": "slides/lec-06.html#select-only-interesting-columns",
    "title": "CISC482 - Lecture06",
    "section": "Select Only Interesting Columns",
    "text": "Select Only Interesting Columns\n\n\n\ninteresting_columns = ['Species', 'Island', 'Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex', 'Date Egg']\ndf = df[interesting_columns]\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Species\n      Island\n      Culmen Length (mm)\n      Culmen Depth (mm)\n      Flipper Length (mm)\n      Body Mass (g)\n      Sex\n      Date Egg\n    \n  \n  \n    \n      0\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n      2007-11-11\n    \n    \n      1\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      2007-11-11\n    \n    \n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      2007-11-16\n    \n    \n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2007-11-16\n    \n    \n      4\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      2007-11-16"
  },
  {
    "objectID": "slides/lec-06.html#rename-columns",
    "href": "slides/lec-06.html#rename-columns",
    "title": "CISC482 - Lecture06",
    "section": "Rename Columns",
    "text": "Rename Columns\n\n\n\nnew_names = ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year']\nmapping = dict(zip(interesting_columns, new_names))\ndf = df.rename(columns=mapping)\ndf.head()\n\n\n\n\n{'Body Mass (g)': 'body_mass_g',\n 'Culmen Depth (mm)': 'bill_depth_mm',\n 'Culmen Length (mm)': 'bill_length_mm',\n 'Date Egg': 'year',\n 'Flipper Length (mm)': 'flipper_length_mm',\n 'Island': 'island',\n 'Sex': 'sex',\n 'Species': 'species'}"
  },
  {
    "objectID": "slides/lec-06.html#rename-columns-output",
    "href": "slides/lec-06.html#rename-columns-output",
    "title": "CISC482 - Lecture06",
    "section": "Rename Columns",
    "text": "Rename Columns\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n      2007-11-11\n    \n    \n      1\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      2007-11-11\n    \n    \n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      2007-11-16\n    \n    \n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      2007-11-16\n    \n    \n      4\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      2007-11-16"
  },
  {
    "objectID": "slides/lec-06.html#remove-nan",
    "href": "slides/lec-06.html#remove-nan",
    "title": "CISC482 - Lecture06",
    "section": "Remove Nan",
    "text": "Remove Nan\n\n\n\ndf = df.dropna()\ndf = df.reset_index(drop=True) # used to be 343, now 333\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 333 entries, 0 to 332\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    object \ndtypes: float64(4), object(4)\nmemory usage: 20.9+ KB"
  },
  {
    "objectID": "slides/lec-06.html#recap",
    "href": "slides/lec-06.html#recap",
    "title": "CISC482 - Lecture06",
    "section": "Recap",
    "text": "Recap\n\nGot raw data by using pd.read_csv(..)\nLook at data\nSelected columns of interest\nRename columns\nTODO\n\nExtract year as integer from string year column\nlower case sex column\nsimplify species name"
  },
  {
    "objectID": "slides/lec-06.html#selecting-data",
    "href": "slides/lec-06.html#selecting-data",
    "title": "CISC482 - Lecture06",
    "section": "Selecting Data",
    "text": "Selecting Data\n\nYou can select a column by using the [] notation\nOne column wil return a series, more than one column will return a new data frame is returned\n\n\n\n\n\ncolumn = df['year']\ncolumn\n\n\n0      2007-11-11\n1      2007-11-11\n2      2007-11-16\n3      2007-11-16\n4      2007-11-16\n          ...    \n328    2009-11-19\n329    2009-11-21\n330    2009-11-21\n331    2009-11-21\n332    2009-11-21\nName: year, Length: 333, dtype: object"
  },
  {
    "objectID": "slides/lec-06.html#selecting-data-view",
    "href": "slides/lec-06.html#selecting-data-view",
    "title": "CISC482 - Lecture06",
    "section": "Selecting Data, View",
    "text": "Selecting Data, View\n\n\n\n\ndf2 = df[['year', 'sex']]\ndf2.head()\n\n\n\n\n\n\n  \n    \n      \n      year\n      sex\n    \n  \n  \n    \n      0\n      2007-11-11\n      MALE\n    \n    \n      1\n      2007-11-11\n      FEMALE\n    \n    \n      2\n      2007-11-16\n      FEMALE\n    \n    \n      3\n      2007-11-16\n      FEMALE\n    \n    \n      4\n      2007-11-16\n      MALE"
  },
  {
    "objectID": "slides/lec-06.html#create-a-new-column",
    "href": "slides/lec-06.html#create-a-new-column",
    "title": "CISC482 - Lecture06",
    "section": "Create a new column",
    "text": "Create a new column\n\n\n\n\ndf2['test'] = 'CISC482'\ndf2.head()\n\n\n\n\n\n\n  \n    \n      \n      year\n      sex\n      test\n    \n  \n  \n    \n      0\n      2007-11-11\n      MALE\n      CISC482\n    \n    \n      1\n      2007-11-11\n      FEMALE\n      CISC482\n    \n    \n      2\n      2007-11-16\n      FEMALE\n      CISC482\n    \n    \n      3\n      2007-11-16\n      FEMALE\n      CISC482\n    \n    \n      4\n      2007-11-16\n      MALE\n      CISC482"
  },
  {
    "objectID": "slides/lec-06.html#changing-column",
    "href": "slides/lec-06.html#changing-column",
    "title": "CISC482 - Lecture06",
    "section": "Changing Column",
    "text": "Changing Column\n\n\n\n\ndf2.loc[:, 'test'] = 'DataScience'\n# df2['test'] = \"Data Science\" # don't do it!\ndf2.head()\n\n\n\n\n\n\n  \n    \n      \n      year\n      sex\n      test\n    \n  \n  \n    \n      0\n      2007-11-11\n      MALE\n      DataScience\n    \n    \n      1\n      2007-11-11\n      FEMALE\n      DataScience\n    \n    \n      2\n      2007-11-16\n      FEMALE\n      DataScience\n    \n    \n      3\n      2007-11-16\n      FEMALE\n      DataScience\n    \n    \n      4\n      2007-11-16\n      MALE\n      DataScience"
  },
  {
    "objectID": "slides/lec-06.html#selecting-some-rows",
    "href": "slides/lec-06.html#selecting-some-rows",
    "title": "CISC482 - Lecture06",
    "section": "Selecting Some Rows",
    "text": "Selecting Some Rows\n\n\n\n\ndf_big_bills = df[df['bill_length_mm'] > 56]\ndf_big_bills\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      178\n      Gentoo penguin (Pygoscelis papua)\n      Biscoe\n      59.6\n      17.0\n      230.0\n      6050.0\n      MALE\n      2007-12-03\n    \n    \n      282\n      Chinstrap penguin (Pygoscelis antarctica)\n      Dream\n      58.0\n      17.8\n      181.0\n      3700.0\n      FEMALE\n      2007-11-30\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nHow would I just select the male penguins\n\n\n\n\n\ndf_male = df[df['sex'] == \"MALE\"]"
  },
  {
    "objectID": "slides/lec-06.html#fixing-the-year",
    "href": "slides/lec-06.html#fixing-the-year",
    "title": "CISC482 - Lecture06",
    "section": "Fixing the Year",
    "text": "Fixing the Year\n\n\n\ndf.loc[:, 'year'] = df['year'].str[:4]\n# df.loc[:, 'year'] = df['year'].apply(lambda x: str(x).split('-')[0])\ndf.head()\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n      2007\n    \n    \n      1\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      2007\n    \n    \n      2\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      2007\n    \n    \n      3\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      2007\n    \n    \n      4\n      Adelie Penguin (Pygoscelis adeliae)\n      Torgersen\n      39.3\n      20.6\n      190.0\n      3650.0\n      MALE\n      2007"
  },
  {
    "objectID": "slides/lec-06.html#fixing-the-species",
    "href": "slides/lec-06.html#fixing-the-species",
    "title": "CISC482 - Lecture06",
    "section": "Fixing the Species",
    "text": "Fixing the Species\n\n\n\nmapping = {\n  \"Adelie Penguin (Pygoscelis adeliae)\": \"Adelie\", \n  \"Gentoo penguin (Pygoscelis papua)\": \"Gentoo\",\n  \"Chinstrap penguin (Pygoscelis antarctica)\": \"Chinstrap\"\n}\ndf.loc[:, 'species'] = df['species'].map(mapping)\n# df.loc[:, 'species'] = df['species'].apply(lambda x: str(x).split('-')[0])\ndf.head()\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n      2007\n    \n    \n      3\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      39.3\n      20.6\n      190.0\n      3650.0\n      MALE\n      2007"
  },
  {
    "objectID": "slides/lec-06.html#fixing-the-sex",
    "href": "slides/lec-06.html#fixing-the-sex",
    "title": "CISC482 - Lecture06",
    "section": "Fixing the sex",
    "text": "Fixing the sex\n\n\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n      year\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      male\n      2007\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      female\n      2007\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      female\n      2007\n    \n    \n      3\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      female\n      2007\n    \n    \n      4\n      Adelie\n      Torgersen\n      39.3\n      20.6\n      190.0\n      3650.0\n      male\n      2007\n    \n  \n\n\n\n\n\n\n\ndf.loc[:, 'sex'] = df['sex'].str.lower()"
  },
  {
    "objectID": "slides/lec-06.html#checking-data-types",
    "href": "slides/lec-06.html#checking-data-types",
    "title": "CISC482 - Lecture06",
    "section": "Checking Data Types",
    "text": "Checking Data Types\n\n\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 333 entries, 0 to 332\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    object \ndtypes: float64(4), object(4)\nmemory usage: 20.9+ KB"
  },
  {
    "objectID": "slides/lec-06.html#checking-data-types-1",
    "href": "slides/lec-06.html#checking-data-types-1",
    "title": "CISC482 - Lecture06",
    "section": "Checking Data Types",
    "text": "Checking Data Types\n\n\n\ndf.loc[:, 'year'] = pd.to_numeric(df['year'])\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 333 entries, 0 to 332\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 20.9+ KB"
  },
  {
    "objectID": "slides/lec-06.html#practice-pandas",
    "href": "slides/lec-06.html#practice-pandas",
    "title": "CISC482 - Lecture06",
    "section": "Practice Pandas",
    "text": "Practice Pandas\nCleaning Data and Graphing\n\n\n\nhttps://jeremybyu.github.io/intro-ds-website"
  },
  {
    "objectID": "slides/lec-04.html#schedule",
    "href": "slides/lec-04.html#schedule",
    "title": "CISC482 - Lecture04",
    "section": "Schedule",
    "text": "Schedule\n\nReading 2-2: Jan 27 @ 12PM, Friday\nReading 2-3: Feb 1 @ 12PM, Wednesday\nHW2: Feb 1 @ Midnight, Wednesday\nReading 3-1: Feb 3 @ 12PM, Friday"
  },
  {
    "objectID": "slides/lec-04.html#cs-faculty-candidate",
    "href": "slides/lec-04.html#cs-faculty-candidate",
    "title": "CISC482 - Lecture04",
    "section": "CS Faculty Candidate",
    "text": "CS Faculty Candidate\n\nMedha Pujari is here today!\nPlease attend a meet and greet at 3:15 in SBSC 112\nExtra Credit!"
  },
  {
    "objectID": "slides/lec-04.html#terms",
    "href": "slides/lec-04.html#terms",
    "title": "CISC482 - Lecture04",
    "section": "Terms",
    "text": "Terms\n\nRandom Process - action or process which results in an outcome determined by chance\nOutcome - one possible result from a random process\nSample Space - set of all possible outcomes of a random process and denoted as \\(S\\)\nEvent - an outcome or collection of outcomes from a sample space. Typically denoted with Capital letters: \\(A,B,C\\), etc.\nProbability of an event A - denoted, \\(P(A)\\), number of outcomes of A divided by the total number of equally likely outcomes in the sample space \\(S\\). How often does \\(A\\) occur in \\(S\\)"
  },
  {
    "objectID": "slides/lec-04.html#visualizing-probability",
    "href": "slides/lec-04.html#visualizing-probability",
    "title": "CISC482 - Lecture04",
    "section": "Visualizing Probability",
    "text": "Visualizing Probability"
  },
  {
    "objectID": "slides/lec-04.html#operations",
    "href": "slides/lec-04.html#operations",
    "title": "CISC482 - Lecture04",
    "section": "Operations",
    "text": "Operations\n\nCompliment of A - denoted not \\(A\\), \\(A'\\), \\(\\bar{A}\\), \\(A^C\\), \\(\\neg A\\)\n\nWe will use \\(A'\\)\n\nUnion of two events \\(A\\) and \\(B\\) is denoted as \\(A\\) or \\(B\\). Consists of all outcomes in \\(A\\) or \\(B\\)\nIntersection of two events \\(A\\) and \\(B\\) is denoted as \\(A\\) and \\(B\\). Consists of only outcomes in \\(A\\) and \\(B\\)"
  },
  {
    "objectID": "slides/lec-04.html#practice",
    "href": "slides/lec-04.html#practice",
    "title": "CISC482 - Lecture04",
    "section": "Practice",
    "text": "Practice\n\n\n\nCompliment\nUnion\nIntersection\nDifference"
  },
  {
    "objectID": "slides/lec-04.html#cheat-sheet",
    "href": "slides/lec-04.html#cheat-sheet",
    "title": "CISC482 - Lecture04",
    "section": "Cheat Sheet",
    "text": "Cheat Sheet"
  },
  {
    "objectID": "slides/lec-04.html#three-foundational-rules",
    "href": "slides/lec-04.html#three-foundational-rules",
    "title": "CISC482 - Lecture04",
    "section": "Three Foundational Rules",
    "text": "Three Foundational Rules\n\n\nThe probability of any event is non-negative, \\(P(A) >= 0\\)\nThe probability of the sample space is \\(P(S) = 1\\)\nIf A and be are disjoint events, \\(P(A \\; or \\; B) = P(A) + P(B)\\)\n\nNo outcomes in common."
  },
  {
    "objectID": "slides/lec-04.html#three-derived-rules",
    "href": "slides/lec-04.html#three-derived-rules",
    "title": "CISC482 - Lecture04",
    "section": "Three Derived Rules",
    "text": "Three Derived Rules\n\n\\(P(A') = 1 - P(A)\\)\n\\(P(A \\; or \\; B) = P(A) + P(B) - P(A \\; and \\; B)\\)\nindependent events: \\(P(A\\; and\\; B) = P(A) * P(B)\\) \n\n\n\n\n\n\n\nTip\n\n\nYou dont need to derive any of these, you just need to know them! Know the 6 rules"
  },
  {
    "objectID": "slides/lec-04.html#practice-1",
    "href": "slides/lec-04.html#practice-1",
    "title": "CISC482 - Lecture04",
    "section": "Practice",
    "text": "Practice\n\n\n\nSize\n1\n2\n3\n4\n5\n6\n7+\n\n\n\n\nProportion\n0.29\n0.35\n0.15\n0.12\n0.06\n0.02\n0.01\n\n\n\n\n\nFind the probability of randomly selecting a household with a size of more than 1\n\n0.71\n\nFind the probability of randomly selecting a household with a size of 1 or more than 1\n\n1.0\n\nFind the probability of randomly selecting a household with a size of 5 or more\n\n0.09\n\nFind the probability of randomly selecting a household with size 1 or 5 or more\n\n0.38\n\nOne household will be randomly selected from all households, and then a second household will be randomly selected from all households. Find the probability that both selected households are of size 1.\n\n0.08"
  },
  {
    "objectID": "slides/lec-04.html#prepare-to-be-amazed",
    "href": "slides/lec-04.html#prepare-to-be-amazed",
    "title": "CISC482 - Lecture04",
    "section": "Prepare to be amazed",
    "text": "Prepare to be amazed\n\nThe probability of an event occurring can also be determined under the condition of knowing another event has occurred.\nA conditioning probability is a measure of the likelihood of one event occurring, given another event occurred\n\nThe conditional probability of event \\(A\\) given event \\(B\\), denoted \\(P(A|B)\\)\n\\[\nP(A|B) = \\frac{P(A\\; and\\; B)}{P(B)} = \\frac{P(A \\cap B)}{P(B)}\n\\]"
  },
  {
    "objectID": "slides/lec-04.html#thinking-independently",
    "href": "slides/lec-04.html#thinking-independently",
    "title": "CISC482 - Lecture04",
    "section": "Thinking Independently",
    "text": "Thinking Independently\n\n\nWhat if we have independent events, \\(A,B\\)\n\\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\n\\(P(A|B) = \\frac{P(A) * P(B)}{P(B)}\\)\n\\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "slides/lec-04.html#conditional-example",
    "href": "slides/lec-04.html#conditional-example",
    "title": "CISC482 - Lecture04",
    "section": "Conditional Example",
    "text": "Conditional Example"
  },
  {
    "objectID": "slides/lec-04.html#bayes-rule",
    "href": "slides/lec-04.html#bayes-rule",
    "title": "CISC482 - Lecture04",
    "section": "Bayes Rule",
    "text": "Bayes Rule\n\nSometimes you don’t have nice table with all these probabilities filled out\nYou may not know \\(P(A \\cap B)\\). Is all lost?\n\nNo Bayes rule to the rescue!\n\n\n\\[\nP(A | B) = \\frac{P(B | A) * P(A)}{P(B)}\n\\]\n\n\n\n\n\n\nTip\n\n\nThis rule is the foundation of data science and machine learning!"
  },
  {
    "objectID": "slides/lec-04.html#example",
    "href": "slides/lec-04.html#example",
    "title": "CISC482 - Lecture04",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/lec-04.html#random-variables",
    "href": "slides/lec-04.html#random-variables",
    "title": "CISC482 - Lecture04",
    "section": "Random Variables",
    "text": "Random Variables\n\nRandom Variable - Defines numerical values for a random processes outcome.\nTypically denote them like: \\(X,Y, Z\\)\nDiscrete vs Continuous - Flip of coin (1 or 0), GPA of students\nProbability Distribution - gives probability of an occurrence for a a random variable\n\nThis distribution can be visualized! We often use histograms."
  },
  {
    "objectID": "slides/lec-04.html#normal-distribution",
    "href": "slides/lec-04.html#normal-distribution",
    "title": "CISC482 - Lecture04",
    "section": "Normal Distribution",
    "text": "Normal Distribution"
  },
  {
    "objectID": "slides/lec-04.html#normal-details",
    "href": "slides/lec-04.html#normal-details",
    "title": "CISC482 - Lecture04",
    "section": "Normal Details",
    "text": "Normal Details"
  },
  {
    "objectID": "slides/lec-04.html#bernoulli-distribution",
    "href": "slides/lec-04.html#bernoulli-distribution",
    "title": "CISC482 - Lecture04",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nTrue or False, 1 or 0, Success or Failure\n\\(\\pi\\), determines the probaility of success\nWhat is \\(\\pi\\) for this bernoulli distribution"
  },
  {
    "objectID": "slides/lec-04.html#binomial-distribution",
    "href": "slides/lec-04.html#binomial-distribution",
    "title": "CISC482 - Lecture04",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA random variable describing the number of “successes” from independent observations of a random process in which the probability of a success is \\(\\pi\\) follows a binomial distribution\nFlip a coin 10 times (trials) count how many heads.\n\nRepeat 10,000 times to create samples\n\n\\(n\\) how many trials, \\(\\pi\\) probability of one success\n\\(\\mu = n * \\pi\\)         \\(\\sigma^2 = n * \\pi * (1- \\pi)\\)"
  },
  {
    "objectID": "slides/lec-04.html#flipping-a-coin-10-times",
    "href": "slides/lec-04.html#flipping-a-coin-10-times",
    "title": "CISC482 - Lecture04",
    "section": "Flipping a Coin 10 Times",
    "text": "Flipping a Coin 10 Times\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nDoes this seem right?"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "We will be using Google Collab for all Class Activities and Homework. Please just use your Springfield College e-mail for access."
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "📖 Read Assignments 5-3"
  },
  {
    "objectID": "weeks/week-7.html#participate",
    "href": "weeks/week-7.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 12 - Regression 3 🖥️ Lecture 13 - Regression 4"
  },
  {
    "objectID": "weeks/week-7.html#practice",
    "href": "weeks/week-7.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 06 - Practice Regression"
  },
  {
    "objectID": "weeks/week-7.html#perform",
    "href": "weeks/week-7.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 4 - Regression"
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "📖 Read Assignments 5-3"
  },
  {
    "objectID": "weeks/week-8.html#participate",
    "href": "weeks/week-8.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 14 - Model Performance 1 🖥️ Lecture 15 - Model Performance 1"
  },
  {
    "objectID": "weeks/week-8.html#practice",
    "href": "weeks/week-8.html#practice",
    "title": "Week 8",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 07 - Model Performance"
  },
  {
    "objectID": "weeks/week-8.html#perform",
    "href": "weeks/week-8.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 5 - Model Performance"
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "📖 Read Assignments 5-1 📖 Read Assignments 5-2"
  },
  {
    "objectID": "weeks/week-6.html#participate",
    "href": "weeks/week-6.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 10 - Regression 1 🖥️ Lecture 11 - Regression 2"
  },
  {
    "objectID": "weeks/week-6.html#practice",
    "href": "weeks/week-6.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 05 - Practice Regression"
  },
  {
    "objectID": "weeks/week-6.html#perform",
    "href": "weeks/week-6.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 4 - Regression"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "📖 Read Assignments 4-2"
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 9 - EDA"
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 04 - Practice Seaborn"
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\nNone"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "📖 Read Assignments 3-2 and 4-1 in Zybooks."
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 7 - Probability Inference\n🖥️ Lecture 8 - Data Wrangling"
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 04 - Practice Seaborn"
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 3 - Cleaning Data, Graphing, Probability"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "📖 Read Assignments 2-3 and 3-1 in Zybooks."
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 5 - Probability Inference\n🖥️ Lecture 6 - Data Wrangling"
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 03 - Practice Pandas"
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 3 - Cleaning Data and Graphing"
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "📖 Read Assignments 2-1 and 2-2 in Zybooks."
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 3 - Probability and Stats\n🖥️ Lecture 4 - Probability and Stats"
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 02 - Practice NumPy"
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 2 - Analyze Data"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus 📖 Read the project description 📖 Read Chapter 1 in Zybook"
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 1 - Welcome to CISC 482\n🖥️ Lecture 2 - What is Data Science"
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\n📋 Class Activity 01 - Practice Mardown"
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n⌨️ HW 1- Practice Markdown"
  }
]