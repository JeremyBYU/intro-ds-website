---
title: "CISC482 - Lecture09"
subtitle: "Exploratory Data Analysis"
author: "Dr. Jeremy Castagno"
footer:  "[https://jeremybyu.github.io/intro-ds-website](https://jeremybyu.github.io/intro-ds-website/)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
    show-slide-number: all 
    chalkboard: true
    code-copy: false
editor: visual
execute:
  freeze: auto

---


```{python}
#| context: setup
#| include: false
import pandas as pd
import seaborn as sns 
import numpy as np
from sklearn.datasets import make_blobs
from palmerpenguins import load_penguins, load_penguins_raw
df = load_penguins()
sns.set_style('whitegrid')
sns.set_context("poster", font_scale=1.25)
np.set_printoptions(precision=1, suppress=True, formatter={'float_kind': "{:.1f}".format})
pd.options.display.float_format = '{:,.2f}'.format
np.random.seed(1)

```

# Class Business


## Schedule

- Reading 5-1: Feb 22 @ 12PM, Wednesday
- Reading 5-2: Feb 24 @ 12PM, Friday
- Topic Ideas - Feb 22 @ Midnight

## Today

- Review Exam
- Review Topic Ideas
- More Exploratory Data Analysis

# Exam Review

## Most Missed Questions

## Solution to Exam

# Topic Ideas

## Purpose

- Find 2-3 datasets that you are interested and are connected to your core signature assignments
- Verify the data is suitable for analysis
- Practice writing concisely and clearly about complex topics

## Requirements

- Data Requirements
- Paper Requirements

## Data Requirements {.smaller}

- At least 100 observations
- At least 8 columns
- At least 6 of the columns must be useful and unique predictor variables.
- At least one variable that can be identified as a reasonable response variable
  - The response variable can be quantitative or categorical.
- Observations should reasonably meet the independence condition.

## Paper Requirements

- Introduction
- Research Question
- Glimpse of Data

## Introduction Section

- State source of data
- Describe when and how it was originally collected (by the original data curator, not necessarily how you found the data).
- Describe the observations and the general characteristics being measured in the data.
- Describe how the data set connect to your Core Studies.

## Research Question

- Describe a research question youâ€™re interested in answering using this data
- Can you accurately predict whether a person will survive in the titanic data set? What features would be most important to make that prediction?

## Glimpse of Data

- Please print out the results of the `info()` function of the dataframe
- Also print out the first few rows of data `head()`

# Exploratory Data Analysis (EDA)

## Steps

1. Understand the Data
    1. Size of the dataset (rows,cols), features (categorical, numerical).
2. Identify Relationships between features
    1. Direction and strength of correlation
3. Describe the shape of the data
    1. Symmetric, Skewed
4. Detect outliers and missing values
    1. Box an Whisker!

## Understand the Data

- Number of Rows, Columns?
- What features are categorical vs numeric?
- Any missing data?

## Example Data

::: {.smaller}
<div data-prevent-swipe>
```{python}
df = load_penguins()
print(df.info())
df.head()
```
</div>
:::

## Relationship 1

```{python}
x = np.arange(30)
noise = np.random.normal(0, 3, 30)
y_pos = x * 2 + noise
ax =sns.scatterplot(x=x, y=y_pos)
ax.set_xlabel("X")
ax.set_ylabel("Y");
```

## Relationship 2

```{python}
x = np.arange(30)
noise = np.random.normal(0, 3, 30)
y_neg = 60 - x * 2 + noise
ax =sns.scatterplot(x=x, y=y_neg)
ax.set_xlabel("X")
ax.set_ylabel("Y");
```

## Relationship 3

```{python}
x = np.arange(30)
noise = np.random.normal(0, 3, 30)
y_none = np.ones(30) * 40
ax =sns.scatterplot(x=x, y=y_none)
ax.set_xlabel("X")
ax.set_ylabel("Y");
```

## Quantifying the Relationship

- **Covariance** - measure of the joint variability of two random variables
- The sign of the covariance, therefore, shows whether it is positive or negative relationship
- $Cov(X,Y)= \frac{\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})}{n}$
- The magnitude doesn't tell you much....we need a way to normalize it....Correlation to the rescue!

## Correlation

- A metric between -1 and +1
- $r(X,Y)= \frac{\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n(x_i - \bar{x})^2 \cdot \sum_{i=1}^n(y_i - \bar{y})}}$

- $r(X,Y)= \frac{Cov(X,Y)}{\sigma_x \cdot \sigma_y}$


## Example Data

```{python}
#| echo: true
#| output-location: column-fragment

data = np.array([
  [1, 2,   -2,     3],
  [2, 4,   -4,     3],
  [3, 3.5, -3.5,   3],
  [4, 7.5, -7.5,   3],
  [5, 10.2, -10.2, 3],
  [6, 12.1, -12.1, 3],
])
cov = np.cov(data, rowvar=False)
print(cov)
print(np.var(data[:, 0], ddof=1))
print(np.var(data[:, 1], ddof=1))
```

## Example Correlation Graph

```{python}
#| echo: true
#| output-location: column-fragment
corr = np.corrcoef(data, rowvar=False)
dataplot = sns.heatmap(corr, cmap="vlag", annot=True)
```

## Secret Weapon

- Now its time to show you my secret weapon
- Dont tell anyone : )
- What I am about to show you single handedly landed me an offer to work at a big company in California
- Now for the story

# The Story

## Background

- My job was to predict **where** on the airport runway the airplane was using cameras
- Specifally your lateral position on the runway

![](./lec09_images/runway.jpg){fig-align="center"}

## The Story (Continued)

::: incremental
- I created a model that predicted cross-track position. 
  - $\hat{CT} = f(\text{FlightState}) = f(\theta, \psi, \phi, \text{image, etc.})$
- We had the **true** CT position (from GPS) to compare my model against. $Error =  \hat{CT} -  CT$
- It worked great *most* of the time!
- However, we kept getting really large errors sometimes
- No obvious pattern?
- WHY!?!?!

:::

## Data

```{python}
#| echo: False
n = 1000
roll = np.random.normal(2, 5, size=n)
pitch = np.random.normal(-3, 4, size=n)
yaw = np.random.normal(0, 15, size=n)
downtracks = np.linspace(0, 1000, num=int(n/4))
downtracks = np.concatenate([downtracks, downtracks[::-1], downtracks, downtracks[::-1]])

crosstracks = 35 * np.sin(5* np.linspace(0, np.pi * 2, num=n))

noise = np.random.normal(0, 0.5, size=n)
ct_error = np.random.poisson(lam=2, size=n) + noise
alt = np.random.normal(200, 0.5, size=n)
noise = np.random.normal(0, 0.75, size=n)
alt = alt + ct_error + noise

df = pd.DataFrame(data={
  'ct_error': ct_error,
  'roll': roll,
  'pitch': pitch,
  'yaw': yaw,
  'downtracks': downtracks,
  'crosstracks': crosstracks,
  'alt': alt + ct_error
})
df_bad = df.iloc[:, :6]
df_bad.head()
```

## Pair Plot

```python
sns.pairplot(df_bad)
```

##

```{python}
#| echo: False
#| output-location: slide
sns.set_context("paper", font_scale=1)
sns.pairplot(df_bad, height=1);
```

## More Data!

```{python}
df.head()
```

## 


```{python}
#| echo: False
#| output-location: slide
sns.set_context("paper", font_scale=1)
sns.pairplot(df, height=1);
```

## The Error

- Long story short, the GPS altitude was broken!
- It was reporting that the airpane was off the ground!
- My algorithm took into account your height off the ground.
- At first, my bosses would not beleive me! It was a $10,000 GPS!
- But the correlation plots and all my subsequent research convinced them

## The True Error

- Someone forgot to renew the subscription service for the High Precision GPS!

# Recap EDA

## Key Workflow and Graphs

- Descriptive Statisitcs
  - Means, quartiles, etc. for each feature
- Histogram of any intresting features
- Shape of Data
- Missing Data
- Find relationship (Correlation)


# Class Activity

## Class Activity

Work on your Topic Idea!







