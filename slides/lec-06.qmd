---
title: "CISC482 - Lecture06"
subtitle: "Data Wrangling"
author: "Dr. Jeremy Castagno"
footer:  "[https://jeremybyu.github.io/intro-ds-website](https://jeremybyu.github.io/intro-ds-website/)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
    show-slide-number: all 
    chalkboard: true
    code-copy: false
editor: visual
execute:
  freeze: auto

---


```{python}
#| context: setup
#| include: false
import pandas as pd
import seaborn as sns 
import numpy as np
from palmerpenguins import load_penguins, load_penguins_raw
sns.set_style('whitegrid')
sns.set_context("poster", font_scale=1.25)
np.set_printoptions(precision=3, suppress=True, formatter={'float_kind': "{:.3f}".format})
np.random.seed(1)

```

# Class Business


## Schedule

- Reading 3-1: Feb 3 @ 12PM, Friday
- Reading 3-2: Feb 8 @ 12PM, Wednesday
- Reading 4-1: Feb 10 @ 12PM, Friday
- HW3: Feb 15 @ Midnight, Wednesday


# Data Wrangling

## Steps

1. **Discovery** - Familiarize  with source data
2. **Structuring** - Transforms features to uniform formats, units, and scales. 
3. **Cleaning** - Removes or replaces missing and outlier data. 
4. **Enriching** - Derives new features from existing features and appends new data from external sources.
5. **Validating** - Verifies that the dataset is internally consistent and accurate
6. **Publishing** - Makes the dataset available to others 


## Example

![](./lec06_images/exmaple_wrangle.png)


## Extract, Transform, Load

- **Extract, Transform, Load (ETL)** is a process that extracts data from *databases*, transforms the data, and loads the data into an **analytic** database.
- Similar to data wrangling: process data, clean, enrich, etc.
- Difference is that data wrangling is more informal, where ETL is a usually a business process or service.

# Pandas

## What is Pandas

::: columns

:::: {.column width="70%"}
- Pandas is an open source Python package
- Widely used for data science/data analysis
- Key idea is organizing data into a **dataframe**
- Tabular data, effecient queries, uses numpy if possible
::::

:::: {.column width="30%"}

![](./lec06_images/pandas_icon.png){.absolute top=150 right=50 width="300px"}
::::

:::

## Loading Pandas from python lists

```{python}
#| echo: true
#| output-location: column
import pandas as pd
d = {'a': [1, 2, 3], 
    'b': [4.0, 5.0, 6.0]
    }
df = pd.DataFrame(data=d)
df
```
- Pandas creates an index automatically (unnamed column)

## Loading Pandas from NumPy


```{python}
#| echo: true
#| output-location: column
d = {'a': np.array([1, 2, 3]), 
    'b': np.array([4.0, 5.0, 6.0])
    }
df = pd.DataFrame(data=d)
df
```
- You can also use NumPy arrays

## CSV Files

```{=html}
<iframe width="1280" height="600" src="https://github.com/mcnakhaee/palmerpenguins/blob/master/palmerpenguins/data/penguins-raw.csv" title="Palmer Penguins CSV File"></iframe>
```
<!-- https://github.com/mcnakhaee/palmerpenguins/blob/master/palmerpenguins/data/penguins-raw.csv -->
<!-- https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv -->

## Loading Pandas from a CSV {.scrollable}

:::{.smaller}
```{python}
#| echo: true
from IPython import display
df = pd.read_csv('https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv')
df.head()  #display.Markdown(df.head().to_markdown())
```
:::

## Pandas Methods - Info

```{python}
#| echo: true
df.info()
```

## Select Only Interesting Columns

::: {.smaller}
```{python}
#| echo: true
from pprint import pprint
interesting_columns = ['Species', 'Island', 'Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex', 'Date Egg']
df = df[interesting_columns]
df.head()
```
::: 

## Rename Columns

::: {.smaller}
```{python}
#| echo: true
new_names = ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year']
mapping = dict(zip(interesting_columns, new_names))
pprint(mapping)
df = df.rename(columns=mapping)
df.head()
```
::: 

## Remove Nan

::: {.smaller}
```{python}
#| echo: true
df = df[~df.isna().any(axis=1)] # quickly see any NA. NA means Null or NaN
df.info()
```
::: 

## Recap

- Got raw data by using `pd.read_csv(..)`
- Looked at data
- Selected columns of interest
- Renamed columns
- TODO
  - Extract year, 








# Class Activity

## Practice Pandas

[Cleaning Data and Graphing](https://colab.research.google.com/drive/1JfP7piEf21u3U-y57Tr_JYk0wMT_0XwS?usp=sharing)